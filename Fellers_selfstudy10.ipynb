{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fellers_selfstudy10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jetshaggy85/info5731/blob/master/Fellers_selfstudy10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zTLUjfJSzSNJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from collections import Counter, defaultdict\n",
        "import math, random, re, glob\n",
        "from functools import partial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "apb9FqfCuZrO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def split_data(data, prob):\n",
        "  \"\"\"split data into fractions [prob, 1 - prob]\"\"\"\n",
        "  results = [], []\n",
        "  for row in data:\n",
        "    results[0 if random.random() < prob else 1].append(row)\n",
        "  return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mI3OHhhByAxm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_test_split(x, y, test_pct):\n",
        "  data = zip(x, y) # pair corresponding values\n",
        "  train, test = split_data(data, 1 - test_pct) # split the data set of pairs\n",
        "  x_train, y_train = zip(*train) # magical un-zip trick\n",
        "  x_test, y_test = zip(*test)\n",
        "  return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3WiHZzmLyBNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b93a3aca-7259-4695-dcaf-fbc72caa3a2b"
      },
      "cell_type": "code",
      "source": [
        "def accuracy(tp, fp, fn, tn):\n",
        "  correct = tp + tn\n",
        "  total = tp + fp + fn + tn\n",
        "  return correct / total\n",
        "print(accuracy(70, 4930, 13930, 981070))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.98114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5-9KPNnIyBKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c71e792f-2201-4849-eb1c-9d5c9aa35c13"
      },
      "cell_type": "code",
      "source": [
        "def precision(tp, fp, fn, tn):\n",
        "  return tp / (tp + fp)\n",
        "print(precision(70, 4930, 13930, 981070))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "52wLpQehyBF9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edb89fc1-dadb-472b-95ba-07d5f1cdbbed"
      },
      "cell_type": "code",
      "source": [
        "def recall(tp, fp, fn, tn):\n",
        "  return tp / (tp + fn)\n",
        "print(recall(70, 4930, 13930, 981070))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qqtfwj8kyBCV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def f1_score(tp, fp, fn, tn):\n",
        "  p = precision(tp, fp, fn, tn)\n",
        "  r = recall(tp, fp, fn, tn)\n",
        "  return 2 * p * r / (p + r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bt3EMzCsyAtH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenize(message):\n",
        "  message = message.lower() # convert to lowercase\n",
        "  all_words = re.findall(\"[a-z0-9']+\", message) # extract the words\n",
        "  return set(all_words) # remove duplicates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-6Jcuiw6yrcW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def count_words(training_set):\n",
        "  \"\"\"training set consists of pairs (message, is_spam)\"\"\"\n",
        "  counts = defaultdict(lambda: [0, 0])\n",
        "  for message, is_spam in training_set:\n",
        "    for word in tokenize(message):\n",
        "      counts[word][0 if is_spam else 1] += 1\n",
        "  return counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9tN1OCkuyrYr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def word_probabilities(counts, total_spams, total_non_spams, k=0.5):\n",
        "  \"\"\"turn the word_counts into a list of triplets\n",
        "  w, p(w | spam) and p(w | ~spam)\"\"\"\n",
        "  return [(w,\n",
        "    (spam + k) / (total_spams + 2 * k),\n",
        "    (non_spam + k) / (total_non_spams + 2 * k))\n",
        "    for w, (spam, non_spam) in counts.iteritems()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aJn_gP0fyrTh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def spam_probability(word_probs, message):\n",
        "  message_words = tokenize(message)\n",
        "  log_prob_if_spam = log_prob_if_not_spam = 0.0\n",
        "  \n",
        "  # iterate through each word in our vocabulary\n",
        "  for word, prob_if_spam, prob_if_not_spam in word_probs:\n",
        "    \n",
        "    # if *word* appears in the message,\n",
        "    # add the log probability of seeing it\n",
        "    if word in message_words:\n",
        "      log_prob_if_spam += math.log(prob_if_spam)\n",
        "      log_prob_if_not_spam += math.log(prob_if_not_spam)\n",
        "    \n",
        "    # if *word* doesn't appear in the message\n",
        "    # add the log probability of _not_ seeing it\n",
        "    # which is log(1 - probability of seeing it)\n",
        "    else:\n",
        "      log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
        "      log_prob_if_not_spam += math.log(1.0 - prob_if_not_spam)\n",
        "\n",
        "  prob_if_spam = math.exp(log_prob_if_spam)\n",
        "  prob_if_not_spam = math.exp(log_prob_if_not_spam)\n",
        "  return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mtpTrP1GyrOf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier:\n",
        "\n",
        "  def __init__(self, k=0.5):\n",
        "    self.k = k\n",
        "    self.word_probs = []\n",
        "\n",
        "  def train(self, training_set):\n",
        "\n",
        "    # count spam and non-spam messages\n",
        "    num_spams = len([is_spam\n",
        "      for message, is_spam in training_set\n",
        "      if is_spam])\n",
        "    num_non_spams = len(training_set) - num_spams\n",
        "\n",
        "    # run training data through our \"pipeline\"\n",
        "    word_counts = count_words(training_set)\n",
        "    self.word_probs = word_probabilities(word_counts,\n",
        "      num_spams,\n",
        "      num_non_spams,\n",
        "      self.k)\n",
        "  def classify(self, message):\n",
        "    return spam_probability(self.word_probs, message)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ofzaMtGyrFb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob, re\n",
        "\n",
        "# modify the path with wherever you've put the files\n",
        "path = r\"C:\\spam\\*\\*\"\n",
        "\n",
        "data = []\n",
        "\n",
        "# glob.glob returns every filename that matches the wildcarded path\n",
        "for fn in glob.glob(path):\n",
        "  is_spam = \"ham\" not in fn\n",
        "  \n",
        "  with open(fn,'r') as file:\n",
        "    for line in file:\n",
        "      if line.startswith(\"Subject:\"):\n",
        "        # remove the leading \"Subject: \" and keep what's left\n",
        "        subject = re.sub(r\"^Subject: \", \"\", line).strip()\n",
        "        data.append((subject, is_spam))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jm-xbApC6D9k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  # triplets (subject, actual is_spam, predicted spam probability)\n",
        "classified = [(subject, is_spam, classifier.classify(subject))\n",
        "  for subject, is_spam in test_data]\n",
        "\n",
        "# assume that spam_probability > 0.5 corresponds to spam prediction\n",
        "# and count the combinations of (actual is_spam, predicted is_spam)\n",
        "counts = Counter((is_spam, spam_probability > 0.5)\n",
        "  for _, is_spam, spam_probability in classified)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GyUxyLcByAo9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def p_spam_given_word(word_prob):\n",
        "  \"\"\"uses bayes's theorem to compute p(spam | message contains word)\"\"\"\n",
        "  \n",
        "  # word_prob is one of the triplets produced by word_probabilities\n",
        "  word, prob_if_spam, prob_if_not_spam = word_prob\n",
        "  return prob_if_spam / (prob_if_spam + prob_if_not_spam)\n",
        "words = sorted(classifier.word_probs, key=p_spam_given_word)\n",
        "\n",
        "spammiest_words = words[-5:]\n",
        "hammiest_words = words[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TuKLduJIyAjY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def drop_final_s(word):\n",
        "  return re.sub(\"s$\", \"\", word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EdF5MfCsyAdT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def entropy(class_probabilities):\n",
        "  \"\"\"given a list of class probabilities, compute the entropy\"\"\"\n",
        "  return sum(-p * math.log(p, 2)\n",
        "    for p in class_probabilities\n",
        "    if p) # ignore zero probabilities"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yK0ispNK6wOF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def class_probabilities(labels):\n",
        "  total_count = len(labels)\n",
        "  return [count / total_count\n",
        "    for count in Counter(labels).values()]\n",
        "def data_entropy(labeled_data):\n",
        "  labels = [label for _, label in labeled_data]\n",
        "  probabilities = class_probabilities(labels)\n",
        "  return entropy(probabilities)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vriiXAyL6wge",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partition_entropy(subsets):\n",
        "  \"\"\"find the entropy from this partition of data into subsets\n",
        "  subsets is a list of lists of labeled data\"\"\"\n",
        "\n",
        "  total_count = sum(len(subset) for subset in subsets)\n",
        "  \n",
        "  return sum( data_entropy(subset) * len(subset) / total_count\n",
        "    for subset in subsets )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "022hainr6wcA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = [\n",
        "({'level':'Senior', 'lang':'Java', 'tweets':'no', 'phd':'no'}, False),\n",
        "({'level':'Senior', 'lang':'Java', 'tweets':'no', 'phd':'yes'}, False),\n",
        "({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'no'}, True),\n",
        "({'level':'Junior', 'lang':'Python', 'tweets':'no', 'phd':'no'}, True),\n",
        "({'level':'Junior', 'lang':'R', 'tweets':'yes', 'phd':'no'}, True),\n",
        "({'level':'Junior', 'lang':'R', 'tweets':'yes', 'phd':'yes'}, False),\n",
        "({'level':'Mid', 'lang':'R', 'tweets':'yes', 'phd':'yes'}, True),\n",
        "({'level':'Senior', 'lang':'Python', 'tweets':'no', 'phd':'no'}, False),\n",
        "({'level':'Senior', 'lang':'R', 'tweets':'yes', 'phd':'no'}, True),\n",
        "({'level':'Junior', 'lang':'Python', 'tweets':'yes', 'phd':'no'}, True),\n",
        "({'level':'Senior', 'lang':'Python', 'tweets':'yes', 'phd':'yes'}, True),\n",
        "({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'yes'}, True),\n",
        "({'level':'Mid', 'lang':'Java', 'tweets':'yes', 'phd':'no'}, True),\n",
        "({'level':'Junior', 'lang':'Python', 'tweets':'no', 'phd':'yes'}, False)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a39J8kQD6wXi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partition_by(inputs, attribute):\n",
        "  \"\"\"each input is a pair (attribute_dict, label).\n",
        "  returns a dict : attribute_value -> inputs\"\"\"\n",
        "  groups = defaultdict(list)\n",
        "  for input in inputs:\n",
        "    key = input[0][attribute] # get the value of the specified attribute\n",
        "    groups[key].append(input) # then add this input to the correct list\n",
        "  return groups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yc_I_1ui6wLD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partition_entropy_by(inputs, attribute):\n",
        "  \"\"\"computes the entropy corresponding to the given partition\"\"\"\n",
        "  partitions = partition_by(inputs, attribute)\n",
        "  return partition_entropy(partitions.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_5TUDhP6wHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "fd9d2988-a964-4172-d91c-523d9175068e"
      },
      "cell_type": "code",
      "source": [
        "for key in ['level','lang','tweets','phd']:\n",
        "  print(key, partition_entropy_by(inputs, key))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "level 0.6935361388961919\n",
            "lang 0.8601317128547441\n",
            "tweets 0.7884504573082896\n",
            "phd 0.8921589282623617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s4OTMxPN6wDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "63f07cc5-6673-4ad5-c1fb-cb548abf3828"
      },
      "cell_type": "code",
      "source": [
        "senior_inputs = [(input, label)\n",
        "  for input, label in inputs if input[\"level\"] == \"Senior\"]\n",
        "\n",
        "for key in ['lang', 'tweets', 'phd']:\n",
        "  print(key, partition_entropy_by(senior_inputs, key))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lang 0.4\n",
            "tweets 0.0\n",
            "phd 0.9509775004326938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8aYzGnu36v8N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classify(tree, input):\n",
        "  \"\"\"classify the input using the given decision tree\"\"\"\n",
        "  \n",
        "  # if this is a leaf node, return its value\n",
        "  if tree in [True, False]:\n",
        "    return tree\n",
        "  \n",
        "  # otherwise this tree consists of an attribute to split on\n",
        "  # and a dictionary whose keys are values of that attribute\n",
        "  # and whose values of are subtrees to consider next\n",
        "  attribute, subtree_dict = tree\n",
        "\n",
        "  subtree_key = input.get(attribute) # None if input is missing attribute\n",
        "  \n",
        "  if subtree_key not in subtree_dict: # if no subtree for key,\n",
        "    subtree_key = None # we'll use the None subtree\n",
        "  \n",
        "  subtree = subtree_dict[subtree_key] # choose the appropriate subtree\n",
        "  return classify(subtree, input) # and use it to classify the input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DVbpfTYF7wiu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_tree_id3(inputs, split_candidates=None):\n",
        "  \n",
        "  # if this is our first pass,\n",
        "  # all keys of the first input are split candidates\n",
        "  if split_candidates is None:\n",
        "    split_candidates = inputs[0][0].keys()\n",
        "  \n",
        "  # count Trues and Falses in the inputs\n",
        "  num_inputs = len(inputs)\n",
        "  num_trues = len([label for item, label in inputs if label])\n",
        "  num_falses = num_inputs - num_trues\n",
        "\n",
        "  if num_trues == 0: return False # no Trues? return a \"False\" leaf\n",
        "  if num_falses == 0: return True # no Falses? return a \"True\" leaf\n",
        "\n",
        "  if not split_candidates: # if no split candidates left\n",
        "    return num_trues >= num_falses # return the majority leaf\n",
        "\n",
        "  # otherwise, split on the best attribute\n",
        "  best_attribute = min(split_candidates,\n",
        "    key=partial(partition_entropy_by, inputs))\n",
        "  \n",
        "  partitions = partition_by(inputs, best_attribute)\n",
        "  new_candidates = [a for a in split_candidates\n",
        "    if a != best_attribute]\n",
        "\n",
        "  # recursively build the subtrees\n",
        "  subtrees = { attribute_value : build_tree_id3(subset, new_candidates)\n",
        "    for attribute_value, subset in partitions.items() }\n",
        "\n",
        "  subtrees[None] = num_trues > num_falses # default case\n",
        "\n",
        "  return (best_attribute, subtrees)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fk0YqCa27xSV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35958092-a2ce-4b40-c1cc-1664ea49882f"
      },
      "cell_type": "code",
      "source": [
        "tree = build_tree_id3(inputs)\n",
        "\n",
        "classify(tree, { \"level\" : \"Junior\",\n",
        "  \"lang\" : \"Java\",\n",
        "  \"tweets\" : \"yes\",\n",
        "  \"phd\" : \"no\"} ) # True\n",
        "\n",
        "classify(tree, { \"level\" : \"Junior\",\n",
        "  \"lang\" : \"Java\",\n",
        "  \"tweets\" : \"yes\",\n",
        "  \"phd\" : \"yes\"} ) # False"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "BHH0Jen-7xOT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3d6012a-79d1-430c-dc85-ba92687496e7"
      },
      "cell_type": "code",
      "source": [
        "classify(tree, { \"level\" : \"Intern\" } ) # True\n",
        "classify(tree, { \"level\" : \"Senior\" } ) # False"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "zCYqwMnF7xIZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forest_classify(trees, input):\n",
        "  votes = [classify(tree, input) for tree in trees]\n",
        "  vote_counts = Counter(votes)\n",
        "  return vote_counts.most_common(1)[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b-SLVxPD7xEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b284764-fca8-4aea-ceb3-a1ced10a38a8"
      },
      "cell_type": "code",
      "source": [
        ">>> def gender_features(word):\n",
        "...     return {'last_letter': word[-1]}\n",
        ">>> gender_features('Shrek')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'last_letter': 'k'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "-6ZFKn1r_yMI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "8ab7ebae-32b7-4167-f744-c2a8a6829639"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        ">>> nltk.download('names')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "8BksfTCeA-4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7701f3db-1bae-4bf8-cb9e-95d064c84392"
      },
      "cell_type": "code",
      "source": [
        " >>> import nltk\n",
        " >>> nltk.download('movie_reviews')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "metadata": {
        "id": "3wUbE8SABezz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f3c08dc2-f813-4bcd-f823-2851720189da"
      },
      "cell_type": "code",
      "source": [
        " >>> import nltk\n",
        " >>> nltk.download('brown')"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "metadata": {
        "id": "2ww777Oz7weE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> from nltk.corpus import names\n",
        ">>> labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
        "... [(name, 'female') for name in names.words('female.txt')])\n",
        ">>> import random\n",
        ">>> random.shuffle(labeled_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hEGHe9_97wZ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
        ">>> train_set, test_set = featuresets[500:], featuresets[:500]\n",
        ">>> classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cR4uXQGD7wUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26954782-5643-4f8f-bebe-df8f47900276"
      },
      "cell_type": "code",
      "source": [
        ">>> classifier.classify(gender_features('Neo'))\n",
        ">>> classifier.classify(gender_features('Trinity'))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'female'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "hIuXzchv7wNQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45445ab9-4799-47b9-b78b-4bcb51c215fe"
      },
      "cell_type": "code",
      "source": [
        ">>> print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KSfbyFEXAHpJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "ffe6fe30-30bc-408a-b96a-add500972794"
      },
      "cell_type": "code",
      "source": [
        ">>> classifier.show_most_informative_features(5)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "             last_letter = 'a'            female : male   =     35.7 : 1.0\n",
            "             last_letter = 'k'              male : female =     30.8 : 1.0\n",
            "             last_letter = 'p'              male : female =     20.9 : 1.0\n",
            "             last_letter = 'f'              male : female =     15.3 : 1.0\n",
            "             last_letter = 'v'              male : female =     10.5 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bYggKCQHAHlE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> from nltk.classify import apply_features\n",
        ">>> train_set = apply_features(gender_features, labeled_names[500:])\n",
        ">>> test_set = apply_features(gender_features, labeled_names[:500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IbmfgUxjAHhM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gender_features2(name):\n",
        "    features = {}\n",
        "    features[\"first_letter\"] = name[0].lower()\n",
        "    features[\"last_letter\"] = name[-1].lower()\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
        "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BhNFhmZpAHdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "outputId": "0b0e8341-7136-47a7-d188-05928b240d41"
      },
      "cell_type": "code",
      "source": [
        "gender_features2('John')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'count(a)': 0,\n",
              " 'count(b)': 0,\n",
              " 'count(c)': 0,\n",
              " 'count(d)': 0,\n",
              " 'count(e)': 0,\n",
              " 'count(f)': 0,\n",
              " 'count(g)': 0,\n",
              " 'count(h)': 1,\n",
              " 'count(i)': 0,\n",
              " 'count(j)': 1,\n",
              " 'count(k)': 0,\n",
              " 'count(l)': 0,\n",
              " 'count(m)': 0,\n",
              " 'count(n)': 1,\n",
              " 'count(o)': 1,\n",
              " 'count(p)': 0,\n",
              " 'count(q)': 0,\n",
              " 'count(r)': 0,\n",
              " 'count(s)': 0,\n",
              " 'count(t)': 0,\n",
              " 'count(u)': 0,\n",
              " 'count(v)': 0,\n",
              " 'count(w)': 0,\n",
              " 'count(x)': 0,\n",
              " 'count(y)': 0,\n",
              " 'count(z)': 0,\n",
              " 'first_letter': 'j',\n",
              " 'has(a)': False,\n",
              " 'has(b)': False,\n",
              " 'has(c)': False,\n",
              " 'has(d)': False,\n",
              " 'has(e)': False,\n",
              " 'has(f)': False,\n",
              " 'has(g)': False,\n",
              " 'has(h)': True,\n",
              " 'has(i)': False,\n",
              " 'has(j)': True,\n",
              " 'has(k)': False,\n",
              " 'has(l)': False,\n",
              " 'has(m)': False,\n",
              " 'has(n)': True,\n",
              " 'has(o)': True,\n",
              " 'has(p)': False,\n",
              " 'has(q)': False,\n",
              " 'has(r)': False,\n",
              " 'has(s)': False,\n",
              " 'has(t)': False,\n",
              " 'has(u)': False,\n",
              " 'has(v)': False,\n",
              " 'has(w)': False,\n",
              " 'has(x)': False,\n",
              " 'has(y)': False,\n",
              " 'has(z)': False,\n",
              " 'last_letter': 'n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "mNBbpmLhAHZE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b166b87-6653-4215-b3ff-1af91d668300"
      },
      "cell_type": "code",
      "source": [
        ">>> featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
        ">>> train_set, test_set = featuresets[500:], featuresets[:500]\n",
        ">>> classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        ">>> print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VgSRaQqEAHTl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> train_names = labeled_names[1500:]\n",
        ">>> devtest_names = labeled_names[500:1500]\n",
        ">>> test_names = labeled_names[:500]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S7CI3TynAHNG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5878196a-5ff8-4afd-a783-5dc79062def5"
      },
      "cell_type": "code",
      "source": [
        ">>> train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
        ">>> devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
        ">>> test_set = [(gender_features(n), gender) for (n, gender) in test_names]\n",
        ">>> classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        ">>> print(nltk.classify.accuracy(classifier, devtest_set))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X8U7Pd-eAHEK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> errors = []\n",
        ">>> for (name, tag) in devtest_names:\n",
        "...     guess = classifier.classify(gender_features(name))\n",
        "...     if guess != tag:\n",
        "...         errors.append( (tag, guess, name) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VVwyywUp7wGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3948
        },
        "outputId": "a0dcee6a-7af9-4bb0-ba60-9a9c9a10e1ab"
      },
      "cell_type": "code",
      "source": [
        ">>> for (tag, guess, name) in sorted(errors):\n",
        "...     print('correct={:<8} guess={:<8s} name={:<30}'.format(tag, guess, name))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct=female   guess=male     name=Aeriell                       \n",
            "correct=female   guess=male     name=Agnes                         \n",
            "correct=female   guess=male     name=Alis                          \n",
            "correct=female   guess=male     name=Angel                         \n",
            "correct=female   guess=male     name=Annabal                       \n",
            "correct=female   guess=male     name=Ardys                         \n",
            "correct=female   guess=male     name=Avis                          \n",
            "correct=female   guess=male     name=Avril                         \n",
            "correct=female   guess=male     name=Ayn                           \n",
            "correct=female   guess=male     name=Bren                          \n",
            "correct=female   guess=male     name=Brit                          \n",
            "correct=female   guess=male     name=Brooks                        \n",
            "correct=female   guess=male     name=Carleen                       \n",
            "correct=female   guess=male     name=Carlynn                       \n",
            "correct=female   guess=male     name=Carmon                        \n",
            "correct=female   guess=male     name=Carol-Jean                    \n",
            "correct=female   guess=male     name=Carroll                       \n",
            "correct=female   guess=male     name=Cathyleen                     \n",
            "correct=female   guess=male     name=Catlin                        \n",
            "correct=female   guess=male     name=Charleen                      \n",
            "correct=female   guess=male     name=Charmion                      \n",
            "correct=female   guess=male     name=Chris                         \n",
            "correct=female   guess=male     name=Christen                      \n",
            "correct=female   guess=male     name=Chrysler                      \n",
            "correct=female   guess=male     name=Clem                          \n",
            "correct=female   guess=male     name=Coral                         \n",
            "correct=female   guess=male     name=Coriss                        \n",
            "correct=female   guess=male     name=Cristin                       \n",
            "correct=female   guess=male     name=Cyb                           \n",
            "correct=female   guess=male     name=Danell                        \n",
            "correct=female   guess=male     name=Dareen                        \n",
            "correct=female   guess=male     name=Dorit                         \n",
            "correct=female   guess=male     name=Drew                          \n",
            "correct=female   guess=male     name=Emlyn                         \n",
            "correct=female   guess=male     name=Emlynn                        \n",
            "correct=female   guess=male     name=Eran                          \n",
            "correct=female   guess=male     name=Eryn                          \n",
            "correct=female   guess=male     name=Estel                         \n",
            "correct=female   guess=male     name=Ethelind                      \n",
            "correct=female   guess=male     name=Evangelin                     \n",
            "correct=female   guess=male     name=Farrand                       \n",
            "correct=female   guess=male     name=Faun                          \n",
            "correct=female   guess=male     name=Fawn                          \n",
            "correct=female   guess=male     name=Fern                          \n",
            "correct=female   guess=male     name=Francis                       \n",
            "correct=female   guess=male     name=Glen                          \n",
            "correct=female   guess=male     name=Glennis                       \n",
            "correct=female   guess=male     name=Grissel                       \n",
            "correct=female   guess=male     name=Hazel                         \n",
            "correct=female   guess=male     name=Heather                       \n",
            "correct=female   guess=male     name=Hesther                       \n",
            "correct=female   guess=male     name=Hildagard                     \n",
            "correct=female   guess=male     name=Honor                         \n",
            "correct=female   guess=male     name=Ingeborg                      \n",
            "correct=female   guess=male     name=Isador                        \n",
            "correct=female   guess=male     name=Ivett                         \n",
            "correct=female   guess=male     name=Jacquelynn                    \n",
            "correct=female   guess=male     name=Janeen                        \n",
            "correct=female   guess=male     name=Jaquelin                      \n",
            "correct=female   guess=male     name=Jessalin                      \n",
            "correct=female   guess=male     name=Jo                            \n",
            "correct=female   guess=male     name=Joannes                       \n",
            "correct=female   guess=male     name=Joelynn                       \n",
            "correct=female   guess=male     name=Jolynn                        \n",
            "correct=female   guess=male     name=Joslyn                        \n",
            "correct=female   guess=male     name=Josselyn                      \n",
            "correct=female   guess=male     name=Karilynn                      \n",
            "correct=female   guess=male     name=Karyn                         \n",
            "correct=female   guess=male     name=Katalin                       \n",
            "correct=female   guess=male     name=Katharyn                      \n",
            "correct=female   guess=male     name=Kaylyn                        \n",
            "correct=female   guess=male     name=Kerrill                       \n",
            "correct=female   guess=male     name=Kial                          \n",
            "correct=female   guess=male     name=Kirstin                       \n",
            "correct=female   guess=male     name=Kylynn                        \n",
            "correct=female   guess=male     name=Lib                           \n",
            "correct=female   guess=male     name=Linell                        \n",
            "correct=female   guess=male     name=Linnell                       \n",
            "correct=female   guess=male     name=Lorrin                        \n",
            "correct=female   guess=male     name=Lulu                          \n",
            "correct=female   guess=male     name=Lynett                        \n",
            "correct=female   guess=male     name=Mabel                         \n",
            "correct=female   guess=male     name=Madelin                       \n",
            "correct=female   guess=male     name=Madelon                       \n",
            "correct=female   guess=male     name=Madlin                        \n",
            "correct=female   guess=male     name=Mair                          \n",
            "correct=female   guess=male     name=Marget                        \n",
            "correct=female   guess=male     name=Mariam                        \n",
            "correct=female   guess=male     name=Maridel                       \n",
            "correct=female   guess=male     name=Marigold                      \n",
            "correct=female   guess=male     name=Maris                         \n",
            "correct=female   guess=male     name=Marlo                         \n",
            "correct=female   guess=male     name=Mavis                         \n",
            "correct=female   guess=male     name=Mead                          \n",
            "correct=female   guess=male     name=Meggan                        \n",
            "correct=female   guess=male     name=Meghann                       \n",
            "correct=female   guess=male     name=Mildred                       \n",
            "correct=female   guess=male     name=Mildrid                       \n",
            "correct=female   guess=male     name=Moreen                        \n",
            "correct=female   guess=male     name=Morgen                        \n",
            "correct=female   guess=male     name=Mureil                        \n",
            "correct=female   guess=male     name=Nell                          \n",
            "correct=female   guess=male     name=Pat                           \n",
            "correct=female   guess=male     name=Pearl                         \n",
            "correct=female   guess=male     name=Persis                        \n",
            "correct=female   guess=male     name=Phyllys                       \n",
            "correct=female   guess=male     name=Renel                         \n",
            "correct=female   guess=male     name=Riannon                       \n",
            "correct=female   guess=male     name=Rochell                       \n",
            "correct=female   guess=male     name=Rozalin                       \n",
            "correct=female   guess=male     name=Ruthann                       \n",
            "correct=female   guess=male     name=Sherilyn                      \n",
            "correct=female   guess=male     name=Sibyl                         \n",
            "correct=female   guess=male     name=Stoddard                      \n",
            "correct=female   guess=male     name=Venus                         \n",
            "correct=female   guess=male     name=Vivian                        \n",
            "correct=female   guess=male     name=Vivyan                        \n",
            "correct=female   guess=male     name=Wandis                        \n",
            "correct=female   guess=male     name=Wileen                        \n",
            "correct=female   guess=male     name=Wren                          \n",
            "correct=male     guess=female   name=Abe                           \n",
            "correct=male     guess=female   name=Ajai                          \n",
            "correct=male     guess=female   name=Andrea                        \n",
            "correct=male     guess=female   name=Arie                          \n",
            "correct=male     guess=female   name=Ashby                         \n",
            "correct=male     guess=female   name=Aubrey                        \n",
            "correct=male     guess=female   name=Bay                           \n",
            "correct=male     guess=female   name=Berkie                        \n",
            "correct=male     guess=female   name=Billie                        \n",
            "correct=male     guess=female   name=Bobbie                        \n",
            "correct=male     guess=female   name=Brice                         \n",
            "correct=male     guess=female   name=Carmine                       \n",
            "correct=male     guess=female   name=Christie                      \n",
            "correct=male     guess=female   name=Christoph                     \n",
            "correct=male     guess=female   name=Clay                          \n",
            "correct=male     guess=female   name=Claybourne                    \n",
            "correct=male     guess=female   name=Corby                         \n",
            "correct=male     guess=female   name=Darby                         \n",
            "correct=male     guess=female   name=Davidde                       \n",
            "correct=male     guess=female   name=Deane                         \n",
            "correct=male     guess=female   name=Demetri                       \n",
            "correct=male     guess=female   name=Denny                         \n",
            "correct=male     guess=female   name=Doyle                         \n",
            "correct=male     guess=female   name=Eustace                       \n",
            "correct=male     guess=female   name=Ferdy                         \n",
            "correct=male     guess=female   name=Filmore                       \n",
            "correct=male     guess=female   name=Georgy                        \n",
            "correct=male     guess=female   name=Gere                          \n",
            "correct=male     guess=female   name=Germaine                      \n",
            "correct=male     guess=female   name=Gordie                        \n",
            "correct=male     guess=female   name=Gregory                       \n",
            "correct=male     guess=female   name=Gustave                       \n",
            "correct=male     guess=female   name=Helmuth                       \n",
            "correct=male     guess=female   name=Hermy                         \n",
            "correct=male     guess=female   name=Hillery                       \n",
            "correct=male     guess=female   name=Howie                         \n",
            "correct=male     guess=female   name=Hymie                         \n",
            "correct=male     guess=female   name=Ira                           \n",
            "correct=male     guess=female   name=Irvine                        \n",
            "correct=male     guess=female   name=Isaiah                        \n",
            "correct=male     guess=female   name=Jeremy                        \n",
            "correct=male     guess=female   name=Jerrome                       \n",
            "correct=male     guess=female   name=Jerzy                         \n",
            "correct=male     guess=female   name=Jeth                          \n",
            "correct=male     guess=female   name=Jimmy                         \n",
            "correct=male     guess=female   name=Jorge                         \n",
            "correct=male     guess=female   name=Judith                        \n",
            "correct=male     guess=female   name=Jule                          \n",
            "correct=male     guess=female   name=Kelly                         \n",
            "correct=male     guess=female   name=Laurance                      \n",
            "correct=male     guess=female   name=Lay                           \n",
            "correct=male     guess=female   name=Lindy                         \n",
            "correct=male     guess=female   name=Luigi                         \n",
            "correct=male     guess=female   name=Luke                          \n",
            "correct=male     guess=female   name=Mace                          \n",
            "correct=male     guess=female   name=Mahesh                        \n",
            "correct=male     guess=female   name=Marietta                      \n",
            "correct=male     guess=female   name=Marlowe                       \n",
            "correct=male     guess=female   name=Martie                        \n",
            "correct=male     guess=female   name=Maurice                       \n",
            "correct=male     guess=female   name=Maxie                         \n",
            "correct=male     guess=female   name=Merry                         \n",
            "correct=male     guess=female   name=Micah                         \n",
            "correct=male     guess=female   name=Mikey                         \n",
            "correct=male     guess=female   name=Mitch                         \n",
            "correct=male     guess=female   name=Montague                      \n",
            "correct=male     guess=female   name=Monty                         \n",
            "correct=male     guess=female   name=Morley                        \n",
            "correct=male     guess=female   name=Murphy                        \n",
            "correct=male     guess=female   name=Mustafa                       \n",
            "correct=male     guess=female   name=Nickey                        \n",
            "correct=male     guess=female   name=Nickie                        \n",
            "correct=male     guess=female   name=Nikolai                       \n",
            "correct=male     guess=female   name=Normie                        \n",
            "correct=male     guess=female   name=Obadiah                       \n",
            "correct=male     guess=female   name=Osborne                       \n",
            "correct=male     guess=female   name=Ozzie                         \n",
            "correct=male     guess=female   name=Partha                        \n",
            "correct=male     guess=female   name=Percy                         \n",
            "correct=male     guess=female   name=Piggy                         \n",
            "correct=male     guess=female   name=Prentice                      \n",
            "correct=male     guess=female   name=Ramsay                        \n",
            "correct=male     guess=female   name=Ray                           \n",
            "correct=male     guess=female   name=Rey                           \n",
            "correct=male     guess=female   name=Ricky                         \n",
            "correct=male     guess=female   name=Roderich                      \n",
            "correct=male     guess=female   name=Rodge                         \n",
            "correct=male     guess=female   name=Rodolph                       \n",
            "correct=male     guess=female   name=Roice                         \n",
            "correct=male     guess=female   name=Ronny                         \n",
            "correct=male     guess=female   name=Rory                          \n",
            "correct=male     guess=female   name=Ruddy                         \n",
            "correct=male     guess=female   name=Sascha                        \n",
            "correct=male     guess=female   name=See                           \n",
            "correct=male     guess=female   name=Shayne                        \n",
            "correct=male     guess=female   name=Shorty                        \n",
            "correct=male     guess=female   name=Skelly                        \n",
            "correct=male     guess=female   name=Sollie                        \n",
            "correct=male     guess=female   name=Solly                         \n",
            "correct=male     guess=female   name=Sonnie                        \n",
            "correct=male     guess=female   name=Stevy                         \n",
            "correct=male     guess=female   name=Tammie                        \n",
            "correct=male     guess=female   name=Tarrance                      \n",
            "correct=male     guess=female   name=Teddie                        \n",
            "correct=male     guess=female   name=Thane                         \n",
            "correct=male     guess=female   name=Thorny                        \n",
            "correct=male     guess=female   name=Tony                          \n",
            "correct=male     guess=female   name=Tray                          \n",
            "correct=male     guess=female   name=Wash                          \n",
            "correct=male     guess=female   name=Westbrooke                    \n",
            "correct=male     guess=female   name=Whitby                        \n",
            "correct=male     guess=female   name=Wojciech                      \n",
            "correct=male     guess=female   name=Yardley                       \n",
            "correct=male     guess=female   name=Zolly                         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u-q9TatcAw_z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> def gender_features(word):\n",
        "...     return {'suffix1': word[-1:],\n",
        "...             'suffix2': word[-2:]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O8gKbrnvAxJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c45fa3b6-0d17-4331-8f2c-eca514acefda"
      },
      "cell_type": "code",
      "source": [
        ">>> train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
        ">>> devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
        ">>> classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        ">>> print(nltk.classify.accuracy(classifier, devtest_set))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y_Md3Y5XAxlU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> from nltk.corpus import movie_reviews\n",
        ">>> documents = [(list(movie_reviews.words(fileid)), category)\n",
        "...              for category in movie_reviews.categories()\n",
        "...              for fileid in movie_reviews.fileids(category)]\n",
        ">>> random.shuffle(documents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O9hU6XMWAxsd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
        "word_features = list(all_words)[:2000]\n",
        "\n",
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['contains({})'.format(word)] = (word in document_words)\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "guT_YeymAx5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c62d3e2d-b9f2-4959-d745-1bef695a48aa"
      },
      "cell_type": "code",
      "source": [
        ">>> print(document_features(movie_reviews.words('pos/cv957_8737.txt'))) "
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'contains(plot)': True, 'contains(:)': True, 'contains(two)': True, 'contains(teen)': False, 'contains(couples)': False, 'contains(go)': False, 'contains(to)': True, 'contains(a)': True, 'contains(church)': False, 'contains(party)': False, 'contains(,)': True, 'contains(drink)': False, 'contains(and)': True, 'contains(then)': True, 'contains(drive)': False, 'contains(.)': True, 'contains(they)': True, 'contains(get)': True, 'contains(into)': True, 'contains(an)': True, 'contains(accident)': False, 'contains(one)': True, 'contains(of)': True, 'contains(the)': True, 'contains(guys)': False, 'contains(dies)': False, 'contains(but)': True, 'contains(his)': True, 'contains(girlfriend)': True, 'contains(continues)': False, 'contains(see)': False, 'contains(him)': True, 'contains(in)': True, 'contains(her)': False, 'contains(life)': False, 'contains(has)': True, 'contains(nightmares)': False, 'contains(what)': True, \"contains(')\": True, 'contains(s)': True, 'contains(deal)': False, 'contains(?)': False, 'contains(watch)': True, 'contains(movie)': True, 'contains(\")': True, 'contains(sorta)': False, 'contains(find)': False, 'contains(out)': True, 'contains(critique)': False, 'contains(mind)': False, 'contains(-)': True, 'contains(fuck)': False, 'contains(for)': True, 'contains(generation)': False, 'contains(that)': True, 'contains(touches)': False, 'contains(on)': True, 'contains(very)': True, 'contains(cool)': False, 'contains(idea)': True, 'contains(presents)': False, 'contains(it)': True, 'contains(bad)': False, 'contains(package)': False, 'contains(which)': True, 'contains(is)': True, 'contains(makes)': False, 'contains(this)': True, 'contains(review)': False, 'contains(even)': False, 'contains(harder)': False, 'contains(write)': False, 'contains(since)': False, 'contains(i)': False, 'contains(generally)': False, 'contains(applaud)': False, 'contains(films)': False, 'contains(attempt)': False, 'contains(break)': False, 'contains(mold)': False, 'contains(mess)': False, 'contains(with)': True, 'contains(your)': False, 'contains(head)': False, 'contains(such)': False, 'contains(()': True, 'contains(lost)': False, 'contains(highway)': False, 'contains(&)': False, 'contains(memento)': False, 'contains())': True, 'contains(there)': True, 'contains(are)': True, 'contains(good)': False, 'contains(ways)': False, 'contains(making)': True, 'contains(all)': True, 'contains(types)': False, 'contains(these)': False, 'contains(folks)': False, 'contains(just)': True, 'contains(didn)': False, 'contains(t)': False, 'contains(snag)': False, 'contains(correctly)': False, 'contains(seem)': False, 'contains(have)': True, 'contains(taken)': False, 'contains(pretty)': False, 'contains(neat)': False, 'contains(concept)': False, 'contains(executed)': False, 'contains(terribly)': False, 'contains(so)': False, 'contains(problems)': True, 'contains(well)': True, 'contains(its)': False, 'contains(main)': False, 'contains(problem)': False, 'contains(simply)': False, 'contains(too)': False, 'contains(jumbled)': False, 'contains(starts)': False, 'contains(off)': False, 'contains(normal)': False, 'contains(downshifts)': False, 'contains(fantasy)': False, 'contains(world)': True, 'contains(you)': True, 'contains(as)': True, 'contains(audience)': False, 'contains(member)': False, 'contains(no)': False, 'contains(going)': False, 'contains(dreams)': False, 'contains(characters)': False, 'contains(coming)': False, 'contains(back)': False, 'contains(from)': True, 'contains(dead)': False, 'contains(others)': True, 'contains(who)': True, 'contains(look)': True, 'contains(like)': True, 'contains(strange)': False, 'contains(apparitions)': False, 'contains(disappearances)': False, 'contains(looooot)': False, 'contains(chase)': True, 'contains(scenes)': False, 'contains(tons)': False, 'contains(weird)': False, 'contains(things)': True, 'contains(happen)': False, 'contains(most)': True, 'contains(not)': True, 'contains(explained)': False, 'contains(now)': False, 'contains(personally)': False, 'contains(don)': False, 'contains(trying)': False, 'contains(unravel)': False, 'contains(film)': False, 'contains(every)': False, 'contains(when)': True, 'contains(does)': False, 'contains(give)': False, 'contains(me)': True, 'contains(same)': True, 'contains(clue)': False, 'contains(over)': False, 'contains(again)': False, 'contains(kind)': True, 'contains(fed)': False, 'contains(up)': False, 'contains(after)': False, 'contains(while)': True, 'contains(biggest)': False, 'contains(obviously)': False, 'contains(got)': True, 'contains(big)': False, 'contains(secret)': False, 'contains(hide)': False, 'contains(seems)': False, 'contains(want)': False, 'contains(completely)': False, 'contains(until)': False, 'contains(final)': False, 'contains(five)': False, 'contains(minutes)': False, 'contains(do)': True, 'contains(make)': True, 'contains(entertaining)': False, 'contains(thrilling)': False, 'contains(or)': False, 'contains(engaging)': False, 'contains(meantime)': False, 'contains(really)': False, 'contains(sad)': False, 'contains(part)': False, 'contains(arrow)': False, 'contains(both)': False, 'contains(dig)': False, 'contains(flicks)': False, 'contains(we)': False, 'contains(actually)': True, 'contains(figured)': False, 'contains(by)': True, 'contains(half)': False, 'contains(way)': True, 'contains(point)': False, 'contains(strangeness)': False, 'contains(did)': False, 'contains(start)': True, 'contains(little)': True, 'contains(bit)': False, 'contains(sense)': False, 'contains(still)': False, 'contains(more)': False, 'contains(guess)': False, 'contains(bottom)': False, 'contains(line)': False, 'contains(movies)': True, 'contains(should)': False, 'contains(always)': False, 'contains(sure)': False, 'contains(before)': False, 'contains(given)': False, 'contains(password)': False, 'contains(enter)': False, 'contains(understanding)': False, 'contains(mean)': False, 'contains(showing)': False, 'contains(melissa)': False, 'contains(sagemiller)': False, 'contains(running)': False, 'contains(away)': False, 'contains(visions)': False, 'contains(about)': True, 'contains(20)': False, 'contains(throughout)': False, 'contains(plain)': False, 'contains(lazy)': False, 'contains(!)': True, 'contains(okay)': False, 'contains(people)': False, 'contains(chasing)': False, 'contains(know)': False, 'contains(need)': False, 'contains(how)': True, 'contains(giving)': False, 'contains(us)': True, 'contains(different)': False, 'contains(offering)': False, 'contains(further)': False, 'contains(insight)': False, 'contains(down)': False, 'contains(apparently)': False, 'contains(studio)': False, 'contains(took)': False, 'contains(director)': False, 'contains(chopped)': False, 'contains(themselves)': False, 'contains(shows)': False, 'contains(might)': False, 'contains(ve)': False, 'contains(been)': False, 'contains(decent)': False, 'contains(here)': True, 'contains(somewhere)': False, 'contains(suits)': False, 'contains(decided)': False, 'contains(turning)': False, 'contains(music)': False, 'contains(video)': False, 'contains(edge)': False, 'contains(would)': False, 'contains(actors)': False, 'contains(although)': False, 'contains(wes)': False, 'contains(bentley)': False, 'contains(seemed)': False, 'contains(be)': True, 'contains(playing)': True, 'contains(exact)': False, 'contains(character)': False, 'contains(he)': True, 'contains(american)': False, 'contains(beauty)': False, 'contains(only)': True, 'contains(new)': False, 'contains(neighborhood)': False, 'contains(my)': False, 'contains(kudos)': False, 'contains(holds)': False, 'contains(own)': True, 'contains(entire)': False, 'contains(feeling)': False, 'contains(unraveling)': False, 'contains(overall)': False, 'contains(doesn)': False, 'contains(stick)': False, 'contains(because)': False, 'contains(entertain)': False, 'contains(confusing)': False, 'contains(rarely)': False, 'contains(excites)': False, 'contains(feels)': False, 'contains(redundant)': False, 'contains(runtime)': False, 'contains(despite)': False, 'contains(ending)': False, 'contains(explanation)': False, 'contains(craziness)': False, 'contains(came)': False, 'contains(oh)': False, 'contains(horror)': False, 'contains(slasher)': False, 'contains(flick)': False, 'contains(packaged)': False, 'contains(someone)': False, 'contains(assuming)': False, 'contains(genre)': False, 'contains(hot)': False, 'contains(kids)': False, 'contains(also)': True, 'contains(wrapped)': False, 'contains(production)': False, 'contains(years)': False, 'contains(ago)': False, 'contains(sitting)': False, 'contains(shelves)': False, 'contains(ever)': True, 'contains(whatever)': False, 'contains(skip)': False, 'contains(where)': True, 'contains(joblo)': False, 'contains(nightmare)': False, 'contains(elm)': False, 'contains(street)': False, 'contains(3)': False, 'contains(7)': False, 'contains(/)': False, 'contains(10)': False, 'contains(blair)': False, 'contains(witch)': False, 'contains(2)': False, 'contains(crow)': False, 'contains(9)': False, 'contains(salvation)': False, 'contains(4)': False, 'contains(stir)': False, 'contains(echoes)': False, 'contains(8)': False, 'contains(happy)': False, 'contains(bastard)': False, 'contains(quick)': True, 'contains(damn)': False, 'contains(y2k)': False, 'contains(bug)': False, 'contains(starring)': False, 'contains(jamie)': False, 'contains(lee)': False, 'contains(curtis)': False, 'contains(another)': False, 'contains(baldwin)': False, 'contains(brother)': False, 'contains(william)': False, 'contains(time)': False, 'contains(story)': False, 'contains(regarding)': False, 'contains(crew)': False, 'contains(tugboat)': False, 'contains(comes)': False, 'contains(across)': False, 'contains(deserted)': False, 'contains(russian)': False, 'contains(tech)': False, 'contains(ship)': False, 'contains(kick)': False, 'contains(power)': False, 'contains(within)': False, 'contains(gore)': False, 'contains(bringing)': False, 'contains(few)': False, 'contains(action)': True, 'contains(sequences)': False, 'contains(virus)': False, 'contains(empty)': False, 'contains(flash)': False, 'contains(substance)': False, 'contains(why)': False, 'contains(was)': False, 'contains(middle)': False, 'contains(nowhere)': False, 'contains(origin)': False, 'contains(pink)': False, 'contains(flashy)': False, 'contains(thing)': False, 'contains(hit)': False, 'contains(mir)': False, 'contains(course)': True, 'contains(donald)': False, 'contains(sutherland)': False, 'contains(stumbling)': False, 'contains(around)': False, 'contains(drunkenly)': False, 'contains(hey)': False, 'contains(let)': False, 'contains(some)': False, 'contains(robots)': False, 'contains(acting)': False, 'contains(below)': False, 'contains(average)': False, 'contains(likes)': False, 'contains(re)': True, 'contains(likely)': False, 'contains(work)': False, 'contains(halloween)': False, 'contains(h20)': False, 'contains(wasted)': False, 'contains(real)': False, 'contains(star)': False, 'contains(stan)': False, 'contains(winston)': False, 'contains(robot)': False, 'contains(design)': False, 'contains(schnazzy)': False, 'contains(cgi)': False, 'contains(occasional)': False, 'contains(shot)': False, 'contains(picking)': False, 'contains(brain)': False, 'contains(if)': True, 'contains(body)': False, 'contains(parts)': False, 'contains(turn)': False, 'contains(otherwise)': False, 'contains(much)': False, 'contains(sunken)': False, 'contains(jaded)': False, 'contains(viewer)': False, 'contains(thankful)': False, 'contains(invention)': False, 'contains(timex)': False, 'contains(indiglo)': False, 'contains(based)': False, 'contains(late)': False, 'contains(1960)': False, 'contains(television)': False, 'contains(show)': False, 'contains(name)': False, 'contains(mod)': False, 'contains(squad)': False, 'contains(tells)': False, 'contains(tale)': False, 'contains(three)': False, 'contains(reformed)': False, 'contains(criminals)': False, 'contains(under)': False, 'contains(employ)': False, 'contains(police)': False, 'contains(undercover)': True, 'contains(however)': True, 'contains(wrong)': True, 'contains(evidence)': False, 'contains(gets)': True, 'contains(stolen)': False, 'contains(immediately)': False, 'contains(suspicion)': False, 'contains(ads)': False, 'contains(cuts)': False, 'contains(claire)': False, 'contains(dane)': False, 'contains(nice)': False, 'contains(hair)': False, 'contains(cute)': False, 'contains(outfits)': False, 'contains(car)': False, 'contains(chases)': False, 'contains(stuff)': False, 'contains(blowing)': False, 'contains(sounds)': False, 'contains(first)': False, 'contains(fifteen)': False, 'contains(quickly)': False, 'contains(becomes)': False, 'contains(apparent)': False, 'contains(certainly)': False, 'contains(slick)': False, 'contains(looking)': False, 'contains(complete)': False, 'contains(costumes)': False, 'contains(isn)': False, 'contains(enough)': False, 'contains(best)': True, 'contains(described)': False, 'contains(cross)': False, 'contains(between)': True, 'contains(hour)': False, 'contains(long)': False, 'contains(cop)': False, 'contains(stretched)': False, 'contains(span)': False, 'contains(single)': False, 'contains(clich)': False, 'contains(matter)': False, 'contains(elements)': False, 'contains(recycled)': False, 'contains(everything)': True, 'contains(already)': False, 'contains(seen)': False, 'contains(nothing)': False, 'contains(spectacular)': False, 'contains(sometimes)': False, 'contains(bordering)': False, 'contains(wooden)': False, 'contains(danes)': False, 'contains(omar)': False, 'contains(epps)': False, 'contains(deliver)': False, 'contains(their)': False, 'contains(lines)': False, 'contains(bored)': False, 'contains(transfers)': False, 'contains(onto)': False, 'contains(escape)': False, 'contains(relatively)': False, 'contains(unscathed)': False, 'contains(giovanni)': False, 'contains(ribisi)': False, 'contains(plays)': False, 'contains(resident)': False, 'contains(crazy)': False, 'contains(man)': False, 'contains(ultimately)': False, 'contains(being)': False, 'contains(worth)': True, 'contains(watching)': False, 'contains(unfortunately)': False, 'contains(save)': False, 'contains(convoluted)': False, 'contains(apart)': False, 'contains(occupying)': False, 'contains(screen)': True, 'contains(young)': False, 'contains(cast)': False, 'contains(clothes)': False, 'contains(hip)': False, 'contains(soundtrack)': False, 'contains(appears)': False, 'contains(geared)': False, 'contains(towards)': False, 'contains(teenage)': False, 'contains(mindset)': False, 'contains(r)': False, 'contains(rating)': False, 'contains(content)': False, 'contains(justify)': False, 'contains(juvenile)': False, 'contains(older)': False, 'contains(information)': False, 'contains(literally)': False, 'contains(spoon)': False, 'contains(hard)': False, 'contains(instead)': False, 'contains(telling)': False, 'contains(dialogue)': False, 'contains(poorly)': False, 'contains(written)': False, 'contains(extremely)': False, 'contains(predictable)': False, 'contains(progresses)': False, 'contains(won)': False, 'contains(care)': False, 'contains(heroes)': False, 'contains(any)': False, 'contains(jeopardy)': False, 'contains(ll)': False, 'contains(aren)': False, 'contains(basing)': False, 'contains(nobody)': False, 'contains(remembers)': False, 'contains(questionable)': False, 'contains(wisdom)': False, 'contains(especially)': True, 'contains(considers)': False, 'contains(target)': False, 'contains(fact)': False, 'contains(number)': False, 'contains(memorable)': False, 'contains(can)': False, 'contains(counted)': False, 'contains(hand)': False, 'contains(missing)': False, 'contains(finger)': False, 'contains(times)': False, 'contains(checked)': False, 'contains(six)': False, 'contains(clear)': False, 'contains(indication)': False, 'contains(them)': True, 'contains(than)': False, 'contains(cash)': False, 'contains(spending)': False, 'contains(dollar)': False, 'contains(judging)': False, 'contains(rash)': False, 'contains(awful)': False, 'contains(seeing)': True, 'contains(avoid)': False, 'contains(at)': False, 'contains(costs)': False, 'contains(quest)': False, 'contains(camelot)': False, 'contains(warner)': False, 'contains(bros)': False, 'contains(feature)': False, 'contains(length)': False, 'contains(fully)': False, 'contains(animated)': False, 'contains(steal)': False, 'contains(clout)': False, 'contains(disney)': False, 'contains(cartoon)': False, 'contains(empire)': False, 'contains(mouse)': False, 'contains(reason)': False, 'contains(worried)': False, 'contains(other)': True, 'contains(recent)': False, 'contains(challenger)': False, 'contains(throne)': False, 'contains(last)': False, 'contains(fall)': False, 'contains(promising)': False, 'contains(flawed)': False, 'contains(20th)': False, 'contains(century)': False, 'contains(fox)': False, 'contains(anastasia)': False, 'contains(hercules)': False, 'contains(lively)': False, 'contains(colorful)': False, 'contains(palate)': False, 'contains(had)': False, 'contains(beat)': False, 'contains(hands)': False, 'contains(crown)': False, 'contains(1997)': False, 'contains(piece)': False, 'contains(animation)': False, 'contains(year)': False, 'contains(contest)': False, 'contains(arrival)': False, 'contains(magic)': False, 'contains(kingdom)': False, 'contains(mediocre)': False, 'contains(--)': True, 'contains(d)': False, 'contains(pocahontas)': False, 'contains(those)': False, 'contains(keeping)': False, 'contains(score)': False, 'contains(nearly)': False, 'contains(dull)': False, 'contains(revolves)': False, 'contains(adventures)': False, 'contains(free)': False, 'contains(spirited)': False, 'contains(kayley)': False, 'contains(voiced)': False, 'contains(jessalyn)': False, 'contains(gilsig)': False, 'contains(early)': True, 'contains(daughter)': False, 'contains(belated)': False, 'contains(knight)': False, 'contains(king)': False, 'contains(arthur)': False, 'contains(round)': False, 'contains(table)': False, 'contains(dream)': False, 'contains(follow)': False, 'contains(father)': False, 'contains(footsteps)': False, 'contains(she)': True, 'contains(chance)': False, 'contains(evil)': False, 'contains(warlord)': False, 'contains(ruber)': False, 'contains(gary)': False, 'contains(oldman)': False, 'contains(ex)': False, 'contains(gone)': False, 'contains(steals)': False, 'contains(magical)': False, 'contains(sword)': False, 'contains(excalibur)': False, 'contains(accidentally)': False, 'contains(loses)': False, 'contains(dangerous)': True, 'contains(booby)': False, 'contains(trapped)': False, 'contains(forest)': False, 'contains(help)': True, 'contains(hunky)': False, 'contains(blind)': False, 'contains(timberland)': False, 'contains(dweller)': False, 'contains(garrett)': False, 'contains(carey)': False, 'contains(elwes)': False, 'contains(headed)': False, 'contains(dragon)': False, 'contains(eric)': False, 'contains(idle)': False, 'contains(rickles)': False, 'contains(arguing)': False, 'contains(itself)': False, 'contains(able)': False, 'contains(medieval)': False, 'contains(sexist)': False, 'contains(prove)': False, 'contains(fighter)': False, 'contains(side)': False, 'contains(pure)': False, 'contains(showmanship)': False, 'contains(essential)': False, 'contains(element)': False, 'contains(expected)': False, 'contains(climb)': False, 'contains(high)': False, 'contains(ranks)': False, 'contains(differentiates)': False, 'contains(something)': False, 'contains(saturday)': False, 'contains(morning)': False, 'contains(subpar)': False, 'contains(instantly)': False, 'contains(forgettable)': False, 'contains(songs)': False, 'contains(integrated)': False, 'contains(computerized)': False, 'contains(footage)': False, 'contains(compare)': False, 'contains(run)': False, 'contains(angry)': False, 'contains(ogre)': False, 'contains(herc)': False, 'contains(battle)': False, 'contains(hydra)': False, 'contains(rest)': False, 'contains(case)': False, 'contains(stink)': False, 'contains(none)': False, 'contains(remotely)': False, 'contains(interesting)': False, 'contains(race)': False, 'contains(bland)': False, 'contains(end)': False, 'contains(tie)': False, 'contains(win)': False, 'contains(comedy)': True, 'contains(shtick)': False, 'contains(awfully)': False, 'contains(cloying)': False, 'contains(least)': True, 'contains(signs)': False, 'contains(pulse)': False, 'contains(fans)': False, \"contains(-')\": False, 'contains(90s)': False, 'contains(tgif)': False, 'contains(will)': True, 'contains(thrilled)': False, 'contains(jaleel)': False, 'contains(urkel)': False, 'contains(white)': False, 'contains(bronson)': False, 'contains(balki)': False, 'contains(pinchot)': False, 'contains(sharing)': False, 'contains(nicely)': False, 'contains(realized)': False, 'contains(though)': False, 'contains(m)': False, 'contains(loss)': False, 'contains(recall)': False, 'contains(specific)': False, 'contains(providing)': False, 'contains(voice)': False, 'contains(talent)': False, 'contains(enthusiastic)': False, 'contains(paired)': False, 'contains(singers)': False, 'contains(sound)': False, 'contains(musical)': False, 'contains(moments)': False, 'contains(jane)': False, 'contains(seymour)': False, 'contains(celine)': False, 'contains(dion)': False, 'contains(must)': False, 'contains(strain)': False, 'contains(through)': False, 'contains(aside)': False, 'contains(children)': False, 'contains(probably)': False, 'contains(adults)': False, 'contains(grievous)': False, 'contains(error)': False, 'contains(lack)': False, 'contains(personality)': False, 'contains(learn)': False, 'contains(goes)': False, 'contains(synopsis)': False, 'contains(mentally)': False, 'contains(unstable)': False, 'contains(undergoing)': False, 'contains(psychotherapy)': False, 'contains(saves)': False, 'contains(boy)': False, 'contains(potentially)': False, 'contains(fatal)': False, 'contains(falls)': False, 'contains(love)': False, 'contains(mother)': False, 'contains(fledgling)': False, 'contains(restauranteur)': False, 'contains(unsuccessfully)': False, 'contains(attempting)': False, 'contains(gain)': False, 'contains(woman)': True, 'contains(favor)': False, 'contains(takes)': False, 'contains(pictures)': False, 'contains(kills)': False, 'contains(comments)': True, 'contains(stalked)': False, 'contains(yet)': False, 'contains(seemingly)': False, 'contains(endless)': True, 'contains(string)': False, 'contains(spurned)': False, 'contains(psychos)': False, 'contains(getting)': True, 'contains(revenge)': False, 'contains(type)': False, 'contains(stable)': False, 'contains(category)': False, 'contains(1990s)': False, 'contains(industry)': False, 'contains(theatrical)': False, 'contains(direct)': False, 'contains(proliferation)': False, 'contains(may)': False, 'contains(due)': False, 'contains(typically)': False, 'contains(inexpensive)': False, 'contains(produce)': False, 'contains(special)': False, 'contains(effects)': False, 'contains(stars)': False, 'contains(serve)': False, 'contains(vehicles)': False, 'contains(nudity)': False, 'contains(allowing)': False, 'contains(frequent)': False, 'contains(night)': False, 'contains(cable)': False, 'contains(wavers)': False, 'contains(slightly)': False, 'contains(norm)': False, 'contains(respect)': False, 'contains(psycho)': False, 'contains(never)': True, 'contains(affair)': False, 'contains(;)': False, 'contains(contrary)': False, 'contains(rejected)': False, 'contains(rather)': False, 'contains(lover)': False, 'contains(wife)': True, 'contains(husband)': False, 'contains(entry)': False, 'contains(doomed)': False, 'contains(collect)': False, 'contains(dust)': False, 'contains(viewed)': False, 'contains(midnight)': False, 'contains(provide)': False, 'contains(suspense)': False, 'contains(sets)': False, 'contains(interspersed)': False, 'contains(opening)': False, 'contains(credits)': False, 'contains(instance)': False, 'contains(serious)': False, 'contains(sounding)': False, 'contains(narrator)': False, 'contains(spouts)': False, 'contains(statistics)': False, 'contains(stalkers)': False, 'contains(ponders)': False, 'contains(cause)': False, 'contains(stalk)': False, 'contains(implicitly)': False, 'contains(implied)': False, 'contains(men)': False, 'contains(shown)': False, 'contains(snapshot)': False, 'contains(actor)': False, 'contains(jay)': False, 'contains(underwood)': False, 'contains(states)': False, 'contains(daryl)': False, 'contains(gleason)': False, 'contains(stalker)': False, 'contains(brooke)': False, 'contains(daniels)': False, 'contains(meant)': False, 'contains(called)': False, 'contains(guesswork)': False, 'contains(required)': False, 'contains(proceeds)': False, 'contains(begins)': False, 'contains(obvious)': False, 'contains(sequence)': False, 'contains(contrived)': False, 'contains(quite)': False, 'contains(brings)': False, 'contains(victim)': False, 'contains(together)': False, 'contains(obsesses)': False, 'contains(follows)': False, 'contains(tries)': True, 'contains(woo)': False, 'contains(plans)': False, 'contains(become)': False, 'contains(desperate)': False, 'contains(elaborate)': False, 'contains(include)': False, 'contains(cliche)': False, 'contains(murdered)': False, 'contains(pet)': False, 'contains(require)': False, 'contains(found)': False, 'contains(exception)': False, 'contains(cat)': False, 'contains(shower)': False, 'contains(events)': False, 'contains(lead)': True, 'contains(inevitable)': False, 'contains(showdown)': False, 'contains(survives)': False, 'contains(invariably)': False, 'contains(conclusion)': False, 'contains(turkey)': False, 'contains(uniformly)': False, 'contains(adequate)': False, 'contains(anything)': False, 'contains(home)': False, 'contains(either)': False, 'contains(turns)': False, 'contains(toward)': False, 'contains(melodrama)': False, 'contains(overdoes)': False, 'contains(words)': False, 'contains(manages)': False, 'contains(creepy)': False, 'contains(pass)': False, 'contains(demands)': False, 'contains(maryam)': False, 'contains(abo)': False, 'contains(close)': False, 'contains(played)': True, 'contains(bond)': False, 'contains(chick)': False, 'contains(living)': False, 'contains(daylights)': False, 'contains(equally)': False, 'contains(title)': False, 'contains(ditzy)': False, 'contains(strong)': False, 'contains(independent)': False, 'contains(business)': False, 'contains(owner)': False, 'contains(needs)': False, 'contains(proceed)': False, 'contains(example)': False, 'contains(suspicions)': False, 'contains(ensure)': False, 'contains(use)': False, 'contains(excuse)': False, 'contains(decides)': False, 'contains(return)': False, 'contains(toolbox)': False, 'contains(left)': False, 'contains(place)': True, 'contains(house)': False, 'contains(leave)': False, 'contains(door)': False, 'contains(answers)': False, 'contains(opens)': False, 'contains(wanders)': False, 'contains(returns)': False, 'contains(enters)': False, 'contains(our)': False, 'contains(heroine)': False, 'contains(danger)': False, 'contains(somehow)': False, 'contains(parked)': False, 'contains(front)': False, 'contains(right)': False, 'contains(oblivious)': False, 'contains(presence)': False, 'contains(inside)': False, 'contains(whole)': False, 'contains(episode)': False, 'contains(places)': False, 'contains(incredible)': False, 'contains(suspension)': False, 'contains(disbelief)': False, 'contains(questions)': False, 'contains(validity)': False, 'contains(intelligence)': False, 'contains(receives)': False, 'contains(highly)': False, 'contains(derivative)': False, 'contains(somewhat)': False, 'contains(boring)': False, 'contains(cannot)': False, 'contains(watched)': False, 'contains(rated)': False, 'contains(mostly)': False, 'contains(several)': False, 'contains(murder)': False, 'contains(brief)': True, 'contains(strip)': False, 'contains(bar)': False, 'contains(offensive)': False, 'contains(many)': True, 'contains(thrillers)': False, 'contains(mood)': False, 'contains(stake)': False, 'contains(else)': False, 'contains(capsule)': True, 'contains(2176)': False, 'contains(planet)': False, 'contains(mars)': False, 'contains(taking)': False, 'contains(custody)': False, 'contains(accused)': False, 'contains(murderer)': False, 'contains(face)': False, 'contains(menace)': False, 'contains(lot)': False, 'contains(fighting)': False, 'contains(john)': False, 'contains(carpenter)': False, 'contains(reprises)': False, 'contains(ideas)': False, 'contains(previous)': False, 'contains(assault)': False, 'contains(precinct)': False, 'contains(13)': False, 'contains(homage)': False, 'contains(himself)': False, 'contains(0)': False, 'contains(+)': False, 'contains(believes)': False, 'contains(fight)': True, 'contains(horrible)': False, 'contains(writer)': False, 'contains(supposedly)': False, 'contains(expert)': False, 'contains(mistake)': False, 'contains(ghosts)': False, 'contains(drawn)': False, 'contains(humans)': False, 'contains(surprisingly)': False, 'contains(low)': False, 'contains(powered)': False, 'contains(alien)': False, 'contains(addition)': False, 'contains(anybody)': False, 'contains(made)': False, 'contains(grounds)': False, 'contains(sue)': False, 'contains(chock)': False, 'contains(full)': False, 'contains(pieces)': False, 'contains(prince)': False, 'contains(darkness)': False, 'contains(surprising)': False, 'contains(managed)': False, 'contains(fit)': False, 'contains(admittedly)': False, 'contains(novel)': False, 'contains(science)': False, 'contains(fiction)': False, 'contains(experience)': False, 'contains(terraformed)': False, 'contains(walk)': False, 'contains(surface)': False, 'contains(without)': False, 'contains(breathing)': False, 'contains(gear)': False, 'contains(budget)': False, 'contains(mentioned)': False, 'contains(gravity)': False, 'contains(increased)': False, 'contains(earth)': False, 'contains(easier)': False, 'contains(society)': False, 'contains(changed)': False, 'contains(advanced)': False, 'contains(culture)': False, 'contains(women)': False, 'contains(positions)': False, 'contains(control)': False, 'contains(view)': False, 'contains(stagnated)': False, 'contains(female)': False, 'contains(beyond)': False, 'contains(minor)': False, 'contains(technological)': False, 'contains(advances)': False, 'contains(less)': False, 'contains(175)': False, 'contains(expect)': False, 'contains(change)': False, 'contains(ten)': False, 'contains(basic)': False, 'contains(common)': False, 'contains(except)': False, 'contains(yes)': False, 'contains(replaced)': False, 'contains(tacky)': False, 'contains(rundown)': False, 'contains(martian)': False, 'contains(mining)': False, 'contains(colony)': False, 'contains(having)': False, 'contains(criminal)': False, 'contains(napolean)': False, 'contains(wilson)': False, 'contains(desolation)': False, 'contains(williams)': False, 'contains(facing)': False, 'contains(hoodlums)': False, 'contains(automatic)': False, 'contains(weapons)': False, 'contains(nature)': False, 'contains(behave)': False, 'contains(manner)': False, 'contains(essentially)': False, 'contains(human)': False, 'contains(savages)': False, 'contains(lapse)': False, 'contains(imagination)': False, 'contains(told)': False, 'contains(flashback)': False, 'contains(entirely)': False, 'contains(filmed)': False, 'contains(almost)': False, 'contains(tones)': False, 'contains(red)': False, 'contains(yellow)': False, 'contains(black)': False, 'contains(powerful)': False, 'contains(scene)': True, 'contains(train)': True, 'contains(rushing)': False, 'contains(heavy)': False, 'contains(sadly)': False, 'contains(buildup)': False, 'contains(terror)': False, 'contains(creates)': False, 'contains(looks)': True, 'contains(fugitive)': False, 'contains(wannabes)': False, 'contains(rock)': False, 'contains(band)': False, 'contains(kiss)': False, 'contains(building)': False, 'contains(bunch)': False, 'contains(sudden)': False, 'contains(jump)': False, 'contains(sucker)': False, 'contains(thinking)': False, 'contains(scary)': False, 'contains(happening)': False, 'contains(standard)': False, 'contains(haunted)': False, 'contains(shock)': False, 'contains(great)': True, 'contains(newer)': False, 'contains(unimpressive)': False, 'contains(digital)': False, 'contains(decapitations)': False, 'contains(fights)': False, 'contains(short)': False, 'contains(stretch)': False, 'contains(release)': False, 'contains(mission)': False, 'contains(panned)': False, 'contains(reviewers)': False, 'contains(better)': False, 'contains(rate)': False, 'contains(scale)': False, 'contains(following)': False, 'contains(showed)': False, 'contains(liked)': False, 'contains(moderately)': False, 'contains(classic)': False, 'contains(comment)': False, 'contains(twice)': False, 'contains(ask)': False, 'contains(yourself)': False, 'contains(8mm)': False, 'contains(eight)': True, 'contains(millimeter)': False, 'contains(wholesome)': False, 'contains(surveillance)': False, 'contains(sight)': False, 'contains(values)': False, 'contains(becoming)': False, 'contains(enmeshed)': False, 'contains(seedy)': False, 'contains(sleazy)': False, 'contains(underworld)': False, 'contains(hardcore)': False, 'contains(pornography)': False, 'contains(bubbling)': False, 'contains(beneath)': False, 'contains(town)': False, 'contains(americana)': False, 'contains(sordid)': False, 'contains(sick)': False, 'contains(depraved)': False, 'contains(necessarily)': False, 'contains(stop)': True, 'contains(order)': False, 'contains(satisfy)': False, 'contains(twisted)': False, 'contains(desires)': False, 'contains(position)': False, 'contains(influence)': False, 'contains(kinds)': False, 'contains(demented)': False, 'contains(talking)': False, 'contains(snuff)': False, 'contains(supposed)': False, 'contains(documentaries)': False, 'contains(victims)': False, 'contains(brutalized)': False, 'contains(killed)': False, 'contains(camera)': False, 'contains(joel)': False, 'contains(schumacher)': False, 'contains(credit)': False, 'contains(batman)': False, 'contains(robin)': False, 'contains(kill)': False, 'contains(forever)': False, 'contains(client)': False, 'contains(thirds)': False, 'contains(unwind)': False, 'contains(fairly)': True, 'contains(conventional)': False, 'contains(persons)': False, 'contains(drama)': False, 'contains(albeit)': False, 'contains(particularly)': False, 'contains(unsavory)': False, 'contains(core)': False, 'contains(threatening)': False, 'contains(along)': True, 'contains(explodes)': False, 'contains(violence)': False, 'contains(think)': False, 'contains(finally)': False, 'contains(tags)': False, 'contains(ridiculous)': False, 'contains(self)': False, 'contains(righteous)': False, 'contains(finale)': False, 'contains(drags)': False, 'contains(unpleasant)': False, 'contains(trust)': False, 'contains(waste)': False, 'contains(hours)': False, 'contains(nicolas)': False, 'contains(snake)': False, 'contains(eyes)': False, 'contains(cage)': False, 'contains(private)': False, 'contains(investigator)': False, 'contains(tom)': False, 'contains(welles)': False, 'contains(hired)': False, 'contains(wealthy)': False, 'contains(philadelphia)': False, 'contains(widow)': False, 'contains(determine)': False, 'contains(whether)': False, 'contains(reel)': False, 'contains(safe)': False, 'contains(documents)': False, 'contains(girl)': False, 'contains(assignment)': True, 'contains(factly)': False, 'contains(puzzle)': False, 'contains(neatly)': False, 'contains(specialized)': False, 'contains(skills)': False, 'contains(training)': False, 'contains(easy)': False, 'contains(cops)': False, 'contains(toilet)': False, 'contains(tanks)': False, 'contains(clues)': False, 'contains(deeper)': False, 'contains(digs)': False, 'contains(investigation)': False, 'contains(obsessed)': False, 'contains(george)': False, 'contains(c)': False, 'contains(scott)': False, 'contains(paul)': False, 'contains(schrader)': False, 'contains(occasionally)': False, 'contains(flickering)': False, 'contains(whirs)': False, 'contains(sprockets)': False, 'contains(winding)': False, 'contains(projector)': False, 'contains(reminding)': False, 'contains(task)': False, 'contains(hints)': False, 'contains(toll)': False, 'contains(lovely)': False, 'contains(catherine)': False, 'contains(keener)': False, 'contains(frustrated)': False, 'contains(cleveland)': False, 'contains(ugly)': False, 'contains(split)': False, 'contains(level)': False, 'contains(harrisburg)': False, 'contains(pa)': False, 'contains(condemn)': False, 'contains(condone)': False, 'contains(subject)': False, 'contains(exploits)': False, 'contains(irony)': False, 'contains(seven)': False, 'contains(scribe)': False, 'contains(andrew)': False, 'contains(kevin)': True, 'contains(walker)': False, 'contains(vision)': False, 'contains(lane)': False, 'contains(limited)': False, 'contains(hollywood)': False, 'contains(product)': False, 'contains(snippets)': False, 'contains(covering)': False, 'contains(later)': False, 'contains(joaquin)': False, 'contains(phoenix)': False, 'contains(far)': False, 'contains(adult)': False, 'contains(bookstore)': False, 'contains(flunky)': False, 'contains(max)': False, 'contains(california)': False, 'contains(cover)': False, 'contains(horrid)': False, 'contains(screened)': False, 'contains(familiar)': False, 'contains(revelation)': False, 'contains(sexual)': False, 'contains(deviants)': False, 'contains(indeed)': False, 'contains(monsters)': False, 'contains(everyday)': False, 'contains(neither)': False, 'contains(super)': False, 'contains(nor)': False, 'contains(shocking)': False, 'contains(banality)': False, 'contains(exactly)': False, 'contains(felt)': False, 'contains(weren)': False, 'contains(nine)': False, 'contains(laughs)': False, 'contains(months)': False, 'contains(terrible)': False, 'contains(mr)': False, 'contains(hugh)': False, 'contains(grant)': False, 'contains(huge)': False, 'contains(dork)': False, 'contains(oral)': False, 'contains(sex)': False, 'contains(prostitution)': False, 'contains(referring)': False, 'contains(bugs)': False, 'contains(annoying)': False, 'contains(adam)': False, 'contains(sandler)': False, 'contains(jim)': False, 'contains(carrey)': False, 'contains(eye)': False, 'contains(flutters)': False, 'contains(nervous)': False, 'contains(smiles)': False, 'contains(slapstick)': False, 'contains(fistfight)': False, 'contains(delivery)': False, 'contains(room)': False, 'contains(culminating)': False, 'contains(joan)': False, 'contains(cusack)': False, 'contains(lap)': False, 'contains(paid)': False, 'contains($)': False, 'contains(60)': False, 'contains(included)': False, 'contains(obscene)': False, 'contains(double)': False, 'contains(entendres)': False, 'contains(obstetrician)': False, 'contains(pregnant)': False, 'contains(pussy)': False, 'contains(size)': False, 'contains(hairs)': False, 'contains(coat)': False, 'contains(nonetheless)': False, 'contains(exchange)': False, 'contains(cookie)': False, 'contains(cutter)': False, 'contains(originality)': False, 'contains(humor)': False, 'contains(successful)': False, 'contains(child)': False, 'contains(psychiatrist)': False, 'contains(psychologist)': False, 'contains(scriptwriters)': False, 'contains(could)': False, 'contains(inject)': False, 'contains(unfunny)': False, 'contains(kid)': False, 'contains(dad)': False, 'contains(asshole)': False, 'contains(eyelashes)': False, 'contains(offers)': False, 'contains(smile)': False, 'contains(responds)': False, 'contains(english)': False, 'contains(accent)': False, 'contains(attitude)': False, 'contains(possibly)': False, 'contains(_huge_)': False, 'contains(beside)': False, 'contains(includes)': False, 'contains(needlessly)': False, 'contains(stupid)': False, 'contains(jokes)': False, 'contains(olds)': False, 'contains(everyone)': False, 'contains(shakes)': False, 'contains(anyway)': False, 'contains(finds)': False, 'contains(usual)': False, 'contains(reaction)': False, 'contains(fluttered)': False, 'contains(paves)': False, 'contains(possible)': False, 'contains(pregnancy)': False, 'contains(birth)': False, 'contains(gag)': False, 'contains(book)': False, 'contains(friend)': False, 'contains(arnold)': True, 'contains(provides)': False, 'contains(cacophonous)': False, 'contains(funny)': True, 'contains(beats)': False, 'contains(costumed)': False, 'contains(arnie)': False, 'contains(dinosaur)': False, 'contains(draw)': False, 'contains(parallels)': False, 'contains(toy)': False, 'contains(store)': False, 'contains(jeff)': False, 'contains(goldblum)': False, 'contains(hid)': False, 'contains(dreadful)': False, 'contains(hideaway)': False, 'contains(artist)': False, 'contains(fear)': False, 'contains(simultaneous)': False, 'contains(longing)': False, 'contains(commitment)': False, 'contains(doctor)': False, 'contains(recently)': False, 'contains(switch)': False, 'contains(veterinary)': False, 'contains(medicine)': False, 'contains(obstetrics)': False, 'contains(joke)': False, 'contains(old)': False, 'contains(foreign)': False, 'contains(guy)': True, 'contains(mispronounces)': False, 'contains(stereotype)': False, 'contains(say)': False, 'contains(yakov)': False, 'contains(smirnov)': False, 'contains(favorite)': False, 'contains(vodka)': False, 'contains(hence)': False, 'contains(take)': False, 'contains(volvo)': False, 'contains(nasty)': False, 'contains(unamusing)': False, 'contains(heads)': False, 'contains(simultaneously)': False, 'contains(groan)': False, 'contains(failure)': False, 'contains(loud)': False, 'contains(failed)': False, 'contains(uninspired)': False, 'contains(lunacy)': False, 'contains(sunset)': False, 'contains(boulevard)': False, 'contains(arrest)': False, 'contains(please)': False, 'contains(caught)': False, 'contains(pants)': False, 'contains(bring)': False, 'contains(theaters)': False, 'contains(faces)': False, 'contains(90)': False, 'contains(forced)': False, 'contains(unauthentic)': False, 'contains(anyone)': False, 'contains(q)': False, 'contains(80)': False, 'contains(sorry)': False, 'contains(money)': False, 'contains(unfulfilled)': False, 'contains(desire)': False, 'contains(spend)': False, 'contains(bucks)': False, 'contains(call)': False, 'contains(road)': False, 'contains(trip)': False, 'contains(walking)': False, 'contains(wounded)': False, 'contains(stellan)': False, 'contains(skarsg)': False, 'contains(rd)': False, 'contains(convincingly)': False, 'contains(zombified)': False, 'contains(drunken)': False, 'contains(loser)': False, 'contains(difficult)': True, 'contains(smelly)': False, 'contains(boozed)': False, 'contains(reliable)': False, 'contains(swedish)': False, 'contains(adds)': False, 'contains(depth)': False, 'contains(significance)': False, 'contains(plodding)': False, 'contains(aberdeen)': False, 'contains(sentimental)': False, 'contains(painfully)': False, 'contains(mundane)': False, 'contains(european)': False, 'contains(playwright)': False, 'contains(august)': False, 'contains(strindberg)': False, 'contains(built)': False, 'contains(career)': False, 'contains(families)': False, 'contains(relationships)': False, 'contains(paralyzed)': False, 'contains(secrets)': False, 'contains(unable)': False, 'contains(express)': False, 'contains(longings)': False, 'contains(accurate)': False, 'contains(reflection)': False, 'contains(strives)': False, 'contains(focusing)': False, 'contains(pairing)': False, 'contains(alcoholic)': False, 'contains(tomas)': False, 'contains(alienated)': False, 'contains(openly)': False, 'contains(hostile)': False, 'contains(yuppie)': False, 'contains(kaisa)': False, 'contains(lena)': False, 'contains(headey)': False, 'contains(gossip)': False, 'contains(haven)': False, 'contains(spoken)': False, 'contains(wouldn)': False, 'contains(norway)': False, 'contains(scotland)': False, 'contains(automobile)': False, 'contains(charlotte)': False, 'contains(rampling)': False, 'contains(sand)': False, 'contains(rotting)': False, 'contains(hospital)': False, 'contains(bed)': False, 'contains(cancer)': False, 'contains(soap)': False, 'contains(opera)': False, 'contains(twist)': False, 'contains(days)': False, 'contains(live)': False, 'contains(blitzed)': False, 'contains(step)': False, 'contains(foot)': False, 'contains(plane)': False, 'contains(hits)': False, 'contains(open)': False, 'contains(loathing)': False, 'contains(each)': True, 'contains(periodic)': False, 'contains(stops)': True, 'contains(puke)': False, 'contains(dashboard)': False, 'contains(whenever)': False, 'contains(muttering)': False, 'contains(rotten)': False, 'contains(turned)': False, 'contains(sloshed)': False, 'contains(viewpoint)': False, 'contains(recognizes)': False, 'contains(apple)': False, 'contains(hasn)': False, 'contains(fallen)': False, 'contains(tree)': False, 'contains(nosebleeds)': False, 'contains(snorting)': False, 'contains(coke)': False, 'contains(sabotages)': False, 'contains(personal)': False, 'contains(indifference)': False, 'contains(restrain)': False, 'contains(vindictive)': False, 'contains(temper)': False, 'contains(ain)': False, 'contains(pair)': False, 'contains(true)': False, 'contains(notes)': False, 'contains(unspoken)': False, 'contains(familial)': False, 'contains(empathy)': False, 'contains(note)': False, 'contains(repetitively)': False, 'contains(bitchy)': False, 'contains(screenwriters)': False, 'contains(kristin)': False, 'contains(amundsen)': False, 'contains(hans)': False, 'contains(petter)': False, 'contains(moland)': False, 'contains(fabricate)': False, 'contains(series)': True, 'contains(contrivances)': False, 'contains(propel)': False, 'contains(forward)': False, 'contains(roving)': False, 'contains(hooligans)': False, 'contains(drunks)': False, 'contains(nosy)': False, 'contains(flat)': False, 'contains(tires)': False, 'contains(figure)': False, 'contains(schematic)': False, 'contains(convenient)': False, 'contains(narrative)': False, 'contains(reach)': False, 'contains(unveil)': False, 'contains(dark)': False, 'contains(past)': False, 'contains(simplistic)': False, 'contains(devices)': False, 'contains(trivialize)': False, 'contains(conflict)': False, 'contains(mainstays)': False, 'contains(wannabe)': False, 'contains(exists)': False, 'contains(purely)': False, 'contains(sake)': False, 'contains(weak)': False, 'contains(unimaginative)': False, 'contains(casting)': False, 'contains(thwarts)': False, 'contains(pivotal)': False, 'contains(role)': False, 'contains(were)': False, 'contains(stronger)': False, 'contains(actress)': False, 'contains(perhaps)': False, 'contains(coast)': True, 'contains(performances)': False, 'contains(moody)': False, 'contains(haunting)': False, 'contains(cinematography)': False, 'contains(rendering)': False, 'contains(pastoral)': False, 'contains(ghost)': False, 'contains(reference)': False, 'contains(certain)': False, 'contains(superior)': False, 'contains(indie)': False, 'contains(intentional)': False, 'contains(busy)': False, 'contains(using)': False, 'contains(furrowed)': False, 'contains(brow)': False, 'contains(convey)': False, 'contains(twitch)': False, 'contains(insouciance)': False, 'contains(paying)': False, 'contains(attention)': False, 'contains(maybe)': False, 'contains(doing)': False, 'contains(reveal)': False, 'contains(worthwhile)': False, 'contains(earlier)': False, 'contains(released)': False, 'contains(2001)': False, 'contains(jonathan)': False, 'contains(nossiter)': False, 'contains(captivating)': False, 'contains(wonders)': False, 'contains(disturbed)': False, 'contains(parental)': False, 'contains(figures)': False, 'contains(bound)': False, 'contains(ceremonial)': False, 'contains(wedlock)': False, 'contains(differences)': False, 'contains(presented)': False, 'contains(significant)': False, 'contains(luminous)': False, 'contains(diva)': False, 'contains(preening)': False, 'contains(static)': False, 'contains(solid)': False, 'contains(performance)': False, 'contains(pathetic)': False, 'contains(drunk)': False, 'contains(emote)': False, 'contains(besides)': False, 'contains(catatonic)': False, 'contains(sorrow)': False, 'contains(genuine)': False, 'contains(ferocity)': False, 'contains(sexually)': False, 'contains(charged)': False, 'contains(frisson)': False, 'contains(during)': False, 'contains(understated)': False, 'contains(confrontations)': False, 'contains(suggest)': False, 'contains(gray)': False, 'contains(zone)': False, 'contains(complications)': False, 'contains(accompany)': False, 'contains(torn)': False, 'contains(romance)': False, 'contains(stifled)': False, 'contains(curiosity)': False, 'contains(thoroughly)': False, 'contains(explores)': False, 'contains(neurotic)': False, 'contains(territory)': False, 'contains(delving)': False, 'contains(americanization)': False, 'contains(greece)': False, 'contains(mysticism)': False, 'contains(illusion)': False, 'contains(deflect)': False, 'contains(pain)': False, 'contains(overloaded)': False, 'contains(willing)': False, 'contains(come)': False, 'contains(traditional)': False, 'contains(ambitious)': False, 'contains(sleepwalk)': False, 'contains(rhythms)': False, 'contains(timing)': False, 'contains(driven)': False, 'contains(stories)': False, 'contains(complexities)': False, 'contains(depressing)': False, 'contains(answer)': False, 'contains(lawrence)': False, 'contains(kasdan)': False, 'contains(trite)': False, 'contains(useful)': False, 'contains(grand)': False, 'contains(canyon)': False, 'contains(steve)': False, 'contains(martin)': False, 'contains(mogul)': False, 'contains(pronounces)': False, 'contains(riddles)': False, 'contains(answered)': False, 'contains(advice)': False, 'contains(heart)': False, 'contains(french)': False, 'contains(sees)': True, 'contains(parents)': False, 'contains(tim)': False, 'contains(roth)': False, 'contains(oops)': False, 'contains(vows)': False, 'contains(taught)': False, 'contains(musketeer)': False, 'contains(dude)': False, 'contains(used)': True, 'contains(fourteen)': False, 'contains(arrgh)': False, 'contains(swish)': False, 'contains(zzzzzzz)': False, 'contains(original)': False, 'contains(lacks)': False, 'contains(energy)': False, 'contains(next)': False, 'contains(hmmmm)': False, 'contains(justin)': False, 'contains(chambers)': False, 'contains(basically)': False, 'contains(uncharismatic)': False, 'contains(version)': False, 'contains(chris)': False, 'contains(o)': False, 'contains(donnell)': False, 'contains(range)': False, 'contains(mena)': False, 'contains(suvari)': False, 'contains(thora)': False, 'contains(birch)': False, 'contains(dungeons)': False, 'contains(dragons)': False, 'contains(miscast)': False, 'contains(deliveries)': False, 'contains(piss)': False, 'contains(poor)': False, 'contains(ms)': False, 'contains(fault)': False, 'contains(definitely)': False, 'contains(higher)': False, 'contains(semi)': False, 'contains(saving)': False, 'contains(grace)': False, 'contains(wise)': False, 'contains(irrepressible)': False, 'contains(once)': True, 'contains(thousand)': False, 'contains(god)': False, 'contains(beg)': False, 'contains(agent)': False, 'contains(marketplace)': False, 'contains(modern)': False, 'contains(day)': True, 'contains(roles)': False, 'contains(romantic)': False, 'contains(gunk)': False, 'contains(alright)': False, 'contains(yeah)': False, 'contains(yikes)': False, 'contains(notches)': False, 'contains(fellas)': False, 'contains(blares)': False, 'contains(ear)': False, 'contains(accentuate)': False, 'contains(annoy)': False, 'contains(important)': False, 'contains(behind)': False, 'contains(recognize)': False, 'contains(epic)': False, 'contains(fluffy)': False, 'contains(rehashed)': False, 'contains(cake)': False, 'contains(created)': False, 'contains(shrewd)': False, 'contains(advantage)': False, 'contains(kung)': True, 'contains(fu)': True, 'contains(phenomenon)': False, 'contains(test)': False, 'contains(dudes)': False, 'contains(keep)': False, 'contains(reading)': False, 'contains(editing)': False, 'contains(shoddy)': False, 'contains(banal)': False, 'contains(stilted)': False, 'contains(plentiful)': False, 'contains(top)': True, 'contains(horse)': False, 'contains(carriage)': False, 'contains(stand)': False, 'contains(opponent)': False, 'contains(scampering)': False, 'contains(cut)': False, 'contains(mouseketeer)': False, 'contains(rope)': False, 'contains(tower)': False, 'contains(jumping)': False, 'contains(chords)': False, 'contains(hanging)': False, 'contains(says)': False, 'contains(14)': False, 'contains(shirt)': False, 'contains(strayed)': False, 'contains(championing)': False, 'contains(fun)': True, 'contains(stretches)': False, 'contains(atrocious)': False, 'contains(lake)': False, 'contains(reminded)': False, 'contains(school)': False, 'contains(cringe)': False, 'contains(musketeers)': False, 'contains(fat)': False, 'contains(raison)': False, 'contains(etre)': False, 'contains(numbers)': False, 'contains(hoping)': False, 'contains(packed)': False, 'contains(stuntwork)': False, 'contains(promoted)': False, 'contains(trailer)': False, 'contains(major)': False, 'contains(swashbuckling)': False, 'contains(beginning)': False, 'contains(finishes)': False, 'contains(juggling)': False, 'contains(ladders)': False, 'contains(ladder)': True, 'contains(definite)': False, 'contains(keeper)': False, 'contains(regurgitated)': False, 'contains(crap)': False, 'contains(tell)': False, 'contains(deneuve)': False, 'contains(placed)': False, 'contains(hullo)': False, 'contains(barely)': False, 'contains(ugh)': False, 'contains(small)': False, 'contains(annoyed)': False, 'contains(trash)': False, 'contains(gang)': False, 'contains(vow)': False, 'contains(stay)': False, 'contains(thank)': False, 'contains(outlaws)': False, 'contains(5)': False, 'contains(crouching)': False, 'contains(tiger)': False, 'contains(hidden)': False, 'contains(matrix)': False, 'contains(replacement)': False, 'contains(killers)': False, 'contains(6)': False, 'contains(romeo)': False, 'contains(die)': False, 'contains(shanghai)': False, 'contains(noon)': False, 'contains(remembered)': False, 'contains(dr)': False, 'contains(hannibal)': False, 'contains(lecter)': False, 'contains(michael)': False, 'contains(mann)': False, 'contains(forensics)': False, 'contains(thriller)': False, 'contains(manhunter)': False, 'contains(scottish)': False, 'contains(brian)': False, 'contains(cox)': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9ZNBKe-vAyEs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dHDkIfLCAySF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c37fe6c4-8b81-4756-c866-d39518578636"
      },
      "cell_type": "code",
      "source": [
        ">>> print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lz5j5VaUAw7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "aa85e79c-8336-4e1c-d861-0e0e0bd429dd"
      },
      "cell_type": "code",
      "source": [
        ">>> classifier.show_most_informative_features(5)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "     contains(stretched) = True              neg : pos    =      9.6 : 1.0\n",
            " contains(unimaginative) = True              neg : pos    =      7.7 : 1.0\n",
            "    contains(schumacher) = True              neg : pos    =      7.4 : 1.0\n",
            "        contains(sexist) = True              neg : pos    =      7.0 : 1.0\n",
            "     contains(atrocious) = True              neg : pos    =      6.6 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "09-RAharAw3D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> from nltk.corpus import brown\n",
        ">>> suffix_fdist = nltk.FreqDist()\n",
        ">>> for word in brown.words():\n",
        "...     word = word.lower()\n",
        "...     suffix_fdist[word[-1:]] += 1\n",
        "...     suffix_fdist[word[-2:]] += 1\n",
        "...     suffix_fdist[word[-3:]] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VRowFUqRAwyY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "956c80d0-9e14-46f0-ab0d-115300fbabed"
      },
      "cell_type": "code",
      "source": [
        "\t\n",
        ">>> common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\n",
        ">>> print(common_suffixes)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of', 'the', 'y', 'r', 'to', 'in', 'f', 'o', 'ed', 'nd', 'is', 'on', 'l', 'g', 'and', 'ng', 'er', 'as', 'ing', 'h', 'at', 'es', 'or', 're', 'it', '``', 'an', \"''\", 'm', ';', 'i', 'ly', 'ion', 'en', 'al', '?', 'nt', 'be', 'hat', 'st', 'his', 'th', 'll', 'le', 'ce', 'by', 'ts', 'me', 've', \"'\", 'se', 'ut', 'was', 'for', 'ent', 'ch', 'k', 'w', 'ld', '`', 'rs', 'ted', 'ere', 'her', 'ne', 'ns', 'ith', 'ad', 'ry', ')', '(', 'te', '--', 'ay', 'ty', 'ot', 'p', 'nce', \"'s\", 'ter', 'om', 'ss', ':', 'we', 'are', 'c', 'ers', 'uld', 'had', 'so', 'ey']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "naAU6FfqBmSB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> def pos_features(word):\n",
        "...     features = {}\n",
        "...     for suffix in common_suffixes:\n",
        "...         features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
        "...     return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "buWTv-dcBmdt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> tagged_words = brown.tagged_words(categories='news')\n",
        ">>> featuresets = [(pos_features(n), g) for (n,g) in tagged_words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-P_1Gh4Bmth",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> size = int(len(featuresets) * 0.1)\n",
        ">>> train_set, test_set = featuresets[size:], featuresets[:size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xa3v4s9zBvtX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#>>> classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
        "#>>> nltk.classify.accuracy(classifier, test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eh6W7BceBm7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86455cc1-7d2d-411c-c9e7-3bc7775aa898"
      },
      "cell_type": "code",
      "source": [
        ">>> classifier.classify(pos_features('cats'))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "metadata": {
        "id": "j02QdjzkBnZC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pos_features(sentence, i):\n",
        "    features = {\"suffix(1)\": sentence[i][-1:],\n",
        "                \"suffix(2)\": sentence[i][-2:],\n",
        "                \"suffix(3)\": sentence[i][-3:]}\n",
        "    if i == 0:\n",
        "        features[\"prev-word\"] = \"<START>\"\n",
        "    else:\n",
        "        features[\"prev-word\"] = sentence[i-1]\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iZA7mngOB_IB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "930b2397-5e35-4206-b555-f7e0a187fa66"
      },
      "cell_type": "code",
      "source": [
        ">>> pos_features(brown.sents()[0], 8)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prev-word': 'an', 'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ion'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "metadata": {
        "id": "1l5lvAxmBnsh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> tagged_sents = brown.tagged_sents(categories='news')\n",
        ">>> featuresets = []\n",
        ">>> for tagged_sent in tagged_sents:\n",
        "...     untagged_sent = nltk.tag.untag(tagged_sent)\n",
        "...     for i, (word, tag) in enumerate(tagged_sent):\n",
        "...         featuresets.append( (pos_features(untagged_sent, i), tag) )\n",
        "\n",
        ">>> size = int(len(featuresets) * 0.1)\n",
        ">>> train_set, test_set = featuresets[size:], featuresets[:size]\n",
        "#>>> classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "#>>> nltk.classify.accuracy(classifier, test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O4LyOs_hBn-l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pos_features(sentence, i, history):\n",
        "     features = {\"suffix(1)\": sentence[i][-1:],\n",
        "                 \"suffix(2)\": sentence[i][-2:],\n",
        "                 \"suffix(3)\": sentence[i][-3:]}\n",
        "     if i == 0:\n",
        "         features[\"prev-word\"] = \"<START>\"\n",
        "         features[\"prev-tag\"] = \"<START>\"\n",
        "     else:\n",
        "         features[\"prev-word\"] = sentence[i-1]\n",
        "         features[\"prev-tag\"] = history[i-1]\n",
        "     return features\n",
        "\n",
        "class ConsecutivePosTagger(nltk.TaggerI):\n",
        "\n",
        "    def __init__(self, train_sents):\n",
        "        train_set = []\n",
        "        for tagged_sent in train_sents:\n",
        "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
        "            history = []\n",
        "            for i, (word, tag) in enumerate(tagged_sent):\n",
        "                featureset = pos_features(untagged_sent, i, history)\n",
        "                train_set.append( (featureset, tag) )\n",
        "                history.append(tag)\n",
        "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "    def tag(self, sentence):\n",
        "        history = []\n",
        "        for i, word in enumerate(sentence):\n",
        "            featureset = pos_features(sentence, i, history)\n",
        "            tag = self.classifier.classify(featureset)\n",
        "            history.append(tag)\n",
        "        return zip(sentence, history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hwEvwgwaBoOW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0e426d8-d57d-4d77-9bbc-ef9c204b78fe"
      },
      "cell_type": "code",
      "source": [
        ">>> tagged_sents = brown.tagged_sents(categories='news')\n",
        ">>> size = int(len(tagged_sents) * 0.1)\n",
        ">>> train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]\n",
        ">>> tagger = ConsecutivePosTagger(train_sents)\n",
        ">>> print(tagger.evaluate(test_sents))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7980528511821975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nzOPm6-_GlJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "382b0ab2-37a5-4815-c52f-751fff2a9bdf"
      },
      "cell_type": "code",
      "source": [
        ">>> import nltk\n",
        ">>> nltk.download('treebank')"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "metadata": {
        "id": "ZxbYnrFbGsvi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a2dd0a1d-fbcb-4ec1-9140-8e76ce679a35"
      },
      "cell_type": "code",
      "source": [
        " >>> import nltk\n",
        " >>> nltk.download('punkt')"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "metadata": {
        "id": "zunhbkRJBoJI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> sents = nltk.corpus.treebank_raw.sents()\n",
        ">>> tokens = []\n",
        ">>> boundaries = set()\n",
        ">>> offset = 0\n",
        ">>> for sent in sents:\n",
        "...     tokens.extend(sent)\n",
        "...     offset += len(sent)\n",
        "...     boundaries.add(offset-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jWWtGKkxAwtp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> def punct_features(tokens, i):\n",
        "...     return {'next-word-capitalized': tokens[i+1][0].isupper(),\n",
        "...             'prev-word': tokens[i-1].lower(),\n",
        "...             'punct': tokens[i],\n",
        "...             'prev-word-is-one-char': len(tokens[i-1]) == 1}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dse-UhjrAwj-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> featuresets = [(punct_features(tokens, i), (i in boundaries))\n",
        "...                for i in range(1, len(tokens)-1)\n",
        "...                if tokens[i] in '.?!']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fUNDUlPbC0tl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb94b896-3e6e-4b10-da9b-707c8fbd7de0"
      },
      "cell_type": "code",
      "source": [
        ">>> size = int(len(featuresets) * 0.1)\n",
        ">>> train_set, test_set = featuresets[size:], featuresets[:size]\n",
        ">>> classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        ">>> nltk.classify.accuracy(classifier, test_set)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.936026936026936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "metadata": {
        "id": "O1jTwUqLC1Y6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def segment_sentences(words):\n",
        "    start = 0\n",
        "    sents = []\n",
        "    for i, word in enumerate(words):\n",
        "        if word in '.?!' and classifier.classify(punct_features(words, i)) == True:\n",
        "            sents.append(words[start:i+1])\n",
        "            start = i+1\n",
        "    if start < len(words):\n",
        "        sents.append(words[start:])\n",
        "    return sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vvN-3-YSG1l4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "fead701e-61d3-4a0d-d7ff-8d1160f12a1f"
      },
      "cell_type": "code",
      "source": [
        ">>> import nltk\n",
        ">>> nltk.download('nps_chat')"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nps_chat.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "metadata": {
        "id": "TuJzXXjYC1Tr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> posts = nltk.corpus.nps_chat.xml_posts()[:10000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FdJZZJAnC1Nj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> def dialogue_act_features(post):\n",
        "...     features = {}\n",
        "...     for word in nltk.word_tokenize(post):\n",
        "...         features['contains({})'.format(word.lower())] = True\n",
        "...     return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nlXRBcn1C1Hj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ffc3e07-9313-4d86-e29b-737061b851a6"
      },
      "cell_type": "code",
      "source": [
        ">>> featuresets = [(dialogue_act_features(post.text), post.get('class'))\n",
        "...                for post in posts]\n",
        ">>> size = int(len(featuresets) * 0.1)\n",
        ">>> train_set, test_set = featuresets[size:], featuresets[:size]\n",
        ">>> classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        ">>> print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YGJ6T6I6C0ox",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rte_features(rtepair):\n",
        "    extractor = nltk.RTEFeatureExtractor(rtepair)\n",
        "    features = {}\n",
        "    features['word_overlap'] = len(extractor.overlap('word'))\n",
        "    features['word_hyp_extra'] = len(extractor.hyp_extra('word'))\n",
        "    features['ne_overlap'] = len(extractor.overlap('ne'))\n",
        "    features['ne_hyp_extra'] = len(extractor.hyp_extra('ne'))\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rBStZqoBHPs2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5ad5ebae-d467-4a1a-8e67-6c753f867c8a"
      },
      "cell_type": "code",
      "source": [
        " >>> import nltk\n",
        " >>> nltk.download('rte')"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/rte.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "metadata": {
        "id": "dRhqHki7C0kU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "d9a50919-b0f6-4f84-d458-7bbf448e1ca9"
      },
      "cell_type": "code",
      "source": [
        ">>> rtepair = nltk.corpus.rte.pairs(['rte3_dev.xml'])[33]\n",
        ">>> extractor = nltk.RTEFeatureExtractor(rtepair)\n",
        ">>> print(extractor.text_words)\n",
        ">>> print(extractor.hyp_words)\n",
        ">>> print(extractor.overlap('word'))\n",
        ">>> print(extractor.overlap('ne'))\n",
        ">>> print(extractor.hyp_extra('word'))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'together', 'Asia', 'Co', 'China', 'was', 'meeting', 'fledgling', 'Russia', 'four', 'Organisation', 'Soviet', 'Iran', 'Davudi', 'central', 'former', 'operation', 'Shanghai', 'association', 'representing', 'terrorism.', 'republics', 'that', 'fight', 'SCO', 'Parviz', 'at', 'binds'}\n",
            "{'member', 'China', 'SCO.'}\n",
            "set()\n",
            "{'China'}\n",
            "{'member'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S4evUL8fC0fD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> import random\n",
        ">>> from nltk.corpus import brown\n",
        ">>> tagged_sents = list(brown.tagged_sents(categories='news'))\n",
        ">>> random.shuffle(tagged_sents)\n",
        ">>> size = int(len(tagged_sents) * 0.1)\n",
        ">>> train_set, test_set = tagged_sents[size:], tagged_sents[:size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4mkPvVtzC0aU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> file_ids = brown.fileids(categories='news')\n",
        ">>> size = int(len(file_ids) * 0.1)\n",
        ">>> train_set = brown.tagged_sents(file_ids[size:])\n",
        ">>> test_set = brown.tagged_sents(file_ids[:size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-CHOUWpNC0Vx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> train_set = brown.tagged_sents(categories='news')\n",
        ">>> test_set = brown.tagged_sents(categories='fiction')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XQGOCy5xC0QG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "def entropy(labels):\n",
        "    freqdist = nltk.FreqDist(labels)\n",
        "    probs = [freqdist.freq(l) for l in freqdist]\n",
        "    return -sum(p * math.log(p,2) for p in probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bTyLV4iwHlGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "05ca951d-d4af-49f4-e0b8-f0ed9b0a575c"
      },
      "cell_type": "code",
      "source": [
        ">>> print(entropy(['male', 'male', 'male', 'male'])) \n",
        ">>> print(entropy(['male', 'female', 'male', 'male']))\n",
        ">>> print(entropy(['female', 'male', 'female', 'male']))\n",
        ">>> print(entropy(['female', 'female', 'male', 'female']))\n",
        ">>> print(entropy(['female', 'female', 'female', 'female'])) "
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.0\n",
            "0.8112781244591328\n",
            "1.0\n",
            "0.8112781244591328\n",
            "-0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jIOdzrZfHlA6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T1NORpdOHk6r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hUhSLBMkHkxs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hSLjrPOKHkrA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pGK1mG9rC0Gg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}